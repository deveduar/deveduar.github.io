---
date: 2025-11-06 19:04
title: algoritmos y tecnicas de computacion
keywords:
source:
status: üåü
Parent: "[[Area-Prog]]"
public_note: "true"
category: Computer Science
tags:
  - computer_Science
  - CS
---
# algoritmos y tecnicas de computacion

- [Computer Science](/computer%20science/computer-science/)
- diagramas UML
## Sort
- T√©cnicas de ordenaci√≥n comunes:
	- **Bubble Sort**: intercambios sucesivos de elementos adyacentes.
	- **Selection Sort**: selecciona el m√≠nimo (o m√°ximo) en cada iteraci√≥n.
	- **Insertion Sort**: inserta cada elemento en su posici√≥n ordenada.
	- **Merge Sort**: divide y conquista, combina sublistas ordenadas.
	- **Quick Sort**: usa pivote para dividir y ordenar recursivamente.
	- **Heap Sort**: utiliza un heap para ordenar de forma eficiente.
- Conceptos:
	- **Estabilidad**: si mantiene el orden relativo de elementos iguales.
	- **In-place**: si no necesita memoria adicional significativa.
	- **Complejidad esperada**:  
		- O(n¬≤) para m√©todos simples.  
		- O(n log n) para m√©todos eficientes (Merge, Quick, Heap).

---

## Search

### BFF vs DFS
- **Breadth-First Search (BFS)**:  
	- Explora por niveles (amplitud).  
	- Usa una **cola (queue)**.  
	- Garantiza la distancia m√≠nima en grafos no ponderados.  
	- Ideal para encontrar caminos cortos o nodos cercanos.
- **Depth-First Search (DFS)**:  
	- Explora en profundidad antes de retroceder.  
	- Usa una **pila (stack)** o recursi√≥n.  
	- Consume menos memoria pero puede desviarse en grafos grandes.
- Comparaci√≥n:
	- BFS -> mejor para **rutas m√°s cortas**.  
	- DFS -> mejor para **detecci√≥n de ciclos**, **componentes conexos** o **b√∫squedas profundas**.

#### Recursos
- Breadth-first search - Wikipedia-Breadth-first_search
- Difference between Binary Tree and Binary Search Tree-difference-between-binary-tree-and-binary-search-tree

---

## backtracking
- T√©cnica de **exploraci√≥n sistem√°tica** que construye soluciones parciales y retrocede cuando no cumplen restricciones.
- Ejemplos cl√°sicos:
	- N-Reinas, Sudoku, laberintos, combinaciones y permutaciones.
- Clave:
	- Retrocede al √∫ltimo punto de decisi√≥n cuando no hay soluci√≥n parcial v√°lida.
- **Valores repetidos**:  
	Evitar duplicados filtrando o aplicando poda en ramas iguales.

#### Recursos
- Vuelta atr√°s - Wikipedia, la enciclopedia libre-Vuelta_atr%C3%A1s
- 2.4 Backtracking  Programaci√≥n, refactoriza tu mente-backtracking

---

## programacion paralela
- Ejecuci√≥n de m√∫ltiples tareas simult√°neamente.  
- Modelos:
	- **Multithreading**: varios hilos en el mismo proceso.
	- **Multiprocessing**: procesos separados, mejor aislamiento.
	- **GPU computing**: paralelismo masivo orientado a datos.
- Conceptos:
	- **Race Conditions**, **Deadlocks**, **Locks**, **Sem√°foros**.
	- **MapReduce**, **Fork/Join**, **Actor Model**.
	- Coordinaci√≥n con **futuros**, **promesas** y **async/await**.
- Relaci√≥n con Recursion: tareas recursivas paralelizables (divide & conquer paralelos).

---

## Recursion
- Funci√≥n que se llama a s√≠ misma hasta alcanzar una **condici√≥n base**.
- Tipos:
	- **Directa** o **indirecta** (a trav√©s de otra funci√≥n).
	- **Tail recursion** optimizable en algunos lenguajes.
- Comparaci√≥n:
	- Recursi√≥n ‚Üí legibilidad.
	- Iteraci√≥n ‚Üí eficiencia (en tiempo y memoria).
- Ejemplo:
{% raw %}
```python
def factorial(n):
	if n == 0:
		return 1
	return n * factorial(n-1)
```
{% endraw %}`

---

## Paso por referencia o paso por valor

* **Paso por valor**: se copia el valor original ‚Üí no se modifica el argumento fuera del √°mbito.
* **Paso por referencia**: se pasa la **direcci√≥n en memoria** ‚Üí los cambios afectan al original.
* **Copia superficial (shallow copy)**: copia referencias, no objetos anidados.
* **Copia profunda (deep copy)**: crea duplicados completos.

---

## UML y diagramas

* **UML** (Unified Modeling Language) incluye:
  * **Diagrama de clases**: relaciones y jerarqu√≠as.
  * **Diagrama de secuencia**: flujo de mensajes/llamadas.
  * **Diagrama de estados**: transiciones seg√∫n eventos.
* Diferencias:
  * UML ‚Üí conjunto de notaciones.
  * Diagramas ‚Üí instancias espec√≠ficas de vista del sistema.

---

## Interfaces, clases abstractas y herencia m√∫ltiple

* **Interfaz**: define contratos sin implementaci√≥n.
* **Clase abstracta**: puede contener implementaci√≥n parcial.
* **Herencia m√∫ltiple**: una clase puede heredar de varias (no siempre recomendable).
* Recomendaci√≥n:
  * Usar **interfaces + composici√≥n** antes que herencia m√∫ltiple.

---

## Acoplamiento y cohesi√≥n

* **Cohesi√≥n**: qu√© tan bien las partes de un m√≥dulo trabajan juntas.
  ‚Üí Alta cohesi√≥n = dise√±o claro y mantenible.
* **Acoplamiento**: dependencia entre m√≥dulos.
  ‚Üí Bajo acoplamiento = mayor independencia.
* Comparaci√≥n:
  * Alta cohesi√≥n + bajo acoplamiento ‚Üí dise√±o ideal.

---

## Previsi√≥n de cambios y efectos

* Capacidad del sistema para **anticipar modificaciones sin romper dependencias**.
* Principios:

  * **Open/Closed**: abierto a extensi√≥n, cerrado a modificaci√≥n.
  * **Liskov**: sustituci√≥n de subtipos.
  * **DI/IoC** facilitan extensibilidad.

---

## DI e IoC (Inversi√≥n de Control)

* **IoC**: delegar la creaci√≥n y control de objetos a un contenedor externo.
* **DI (Dependency Injection)**: forma espec√≠fica de IoC donde las dependencias se inyectan.
* Ventajas:

  * Menor acoplamiento, mayor testabilidad.
  * Facilita **mocking** y **m√≥dulos intercambiables**.
* Tipos:

  * Constructor, setter o interface injection.

---

## Composici√≥n vs herencia

* **Composici√≥n**: objetos que contienen otros para delegar comportamiento.
* **Herencia**: especializaci√≥n de una clase base.
* Diferencias:

  * Composici√≥n ‚Üí flexible, din√°mica.
  * Herencia ‚Üí r√≠gida, jer√°rquica.
* Principio: *"Prefer composition over inheritance."*

---

## Idempotencia

* Operaci√≥n que puede repetirse sin alterar el resultado final.
* Ejemplo:

  * HTTP PUT y DELETE deben ser idempotentes.
* √ötil en sistemas distribuidos, transacciones y APIs.

---

## Callbacks y funciones acumuladoras

* **Callback**: funci√≥n pasada como argumento que se ejecuta tras cierto evento.
* **Funci√≥n acumuladora**: aplica operaciones sucesivas sobre una colecci√≥n (reduce, fold).
* Ejemplo en [javascript](/desarrollo%20web/javascript/):

{% raw %}
```javascript
const sum = arr => arr.reduce((acc, val) => acc + val, 0);
```
{% endraw %}

* Riesgos: *callback hell* ‚Üí mitigado por promesas y `async/await`.

---

## HOF (Higher Order Functions)

* Funciones que **reciben o retornan otras funciones**.
* Ejemplos: `map`, `filter`, `reduce`.
* Ventajas:

  * Composici√≥n funcional.
  * Reutilizaci√≥n de l√≥gica.
* Base de [PF Programaci√≥n Funcional](/computer%20science/pf-programaci-n-funcional/) junto a **inmutabilidad** y **funciones puras**.

---

## NPI (Notaci√≥n Polaca Inversa) [mates](/uncategorized/mates/)

* Notaci√≥n en la que los operadores se colocan **despu√©s** de los operandos.

  * Ejemplo: `3 4 +` en lugar de `3 + 4`.
* Evaluaci√≥n mediante **pila (stack)**.
* Algoritmo t√≠pico:

{% raw %}
```python
def eval_rpn(tokens):
	stack = []
	for token in tokens:
		if token.isdigit():
			stack.append(float(token))
		else:
			b = stack.pop()
			a = stack.pop()
			if token == '+': stack.append(a + b)
			elif token == '-': stack.append(a - b)
			elif token == '*': stack.append(a * b)
			elif token == '/': stack.append(a / b)
	return stack[0]
```
{% endraw %}

* Usos:
  * Evaluaci√≥n de expresiones.
  * Compiladores, int√©rpretes y calculadoras.

# algoritmos y tecnicas de computacion (expansi√≥n avanzada)

## Complejidad y eficiencia algor√≠tmica
- **Notaciones de complejidad**:
	- O(1): constante  
	- O(log n): logar√≠tmica (b√∫squeda binaria)  
	- O(n): lineal (recorridos simples)  
	- O(n log n): eficiente (ordenamientos √≥ptimos)  
	- O(n¬≤) o peor: cuadr√°tica (anidaci√≥n excesiva)
- **An√°lisis de tiempo vs espacio**: equilibrio entre rendimiento y consumo de memoria.
- **Trade-offs**: usar estructuras o t√©cnicas m√°s costosas en memoria para mejorar la velocidad (ej: tablas hash).
- Conceptos complementarios:
	- **Amortized complexity**  
	- **Big-Omega (Œ©)**: l√≠mite inferior.  
	- **Big-Theta (Œò)**: comportamiento promedio.  
	- **Big-O (O)**: l√≠mite superior.

---

## Estructuras y t√©cnicas complementarias de b√∫squeda y ordenaci√≥n

### B√∫squeda binaria
- Requiere lista ordenada. Divide el espacio de b√∫squeda a la mitad en cada iteraci√≥n.
- Complejidad: **O(log n)**.
{% raw %}
```python
def binary_search(arr, target):
	left, right = 0, len(arr) - 1
	while left <= right:
		mid = (left + right) // 2
		if arr[mid] == target:
			return mid
		elif arr[mid] < target:
			left = mid + 1
		else:
			right = mid - 1
	return -1
```
{% endraw %}`

### Hashing

* Mapeo de claves a posiciones mediante una funci√≥n hash.
* Ideal para b√∫squedas O(1) promedio.
* Colisiones:

  * **Encadenamiento (chaining)** o **direcci√≥n abierta (open addressing)**.
* Base de Tablas hash y caches.

### Ordenaci√≥n h√≠brida

* Algoritmos modernos (como **Timsort**) combinan **Merge Sort + Insertion Sort** seg√∫n el tama√±o de las sublistas.
* Mejora el rendimiento en datos parcialmente ordenados.

---

## T√©cnicas avanzadas de exploraci√≥n y optimizaci√≥n

### Branch and Bound

* Extiende backtracking con **funci√≥n de coste** para podar ramas ineficientes.
* Usado en problemas de optimizaci√≥n (viajante, knapsack, scheduling).

### Programaci√≥n din√°mica

* Divide el problema en subproblemas superpuestos y almacena resultados parciales.
* Requiere **estructura recursiva + subproblemas repetidos**.
* Ejemplo cl√°sico: Fibonacci con memoizaci√≥n.

{% raw %}
```python
def fib(n, memo={}):
	if n in memo: return memo[n]
	if n <= 1: return n
	memo[n] = fib(n-1, memo) + fib(n-2, memo)
	return memo[n]
```
{% endraw %}

* Claves:

  * **Top-down (memoization)**
  * **Bottom-up (tabulation)**
  * Optimizaci√≥n de espacio mediante reutilizaci√≥n de estados.

---

## Grafos y algoritmos asociados

* Representaciones:

  * Matriz de adyacencia.
  * Lista de adyacencia.
* Algoritmos fundamentales:

  * **Dijkstra** (caminos m√≠nimos, sin pesos negativos).
  * **Bellman-Ford** (con pesos negativos).
  * **A*** (b√∫squeda heur√≠stica con funci√≥n `f = g + h`).
  * **Kruskal / Prim** (√°rbol de expansi√≥n m√≠nima).
  * **Topological Sort** (ordenaci√≥n de tareas con dependencias).
* Aplicaciones:

  * Ruteo, planificaci√≥n, an√°lisis de dependencias, redes.

---

## Concurrencia, paralelismo y asincron√≠a

* Diferencias:

  * **Concurrencia**: m√∫ltiples tareas *en progreso* (no necesariamente simult√°neas).
  * **Paralelismo**: ejecuci√≥n *real* en simult√°neo (m√∫ltiples n√∫cleos).
  * **Asincron√≠a**: no bloqueante, orientada a eventos (ej: [javascript](/desarrollo%20web/javascript/) y su event loop).
* Patrones:

  * **Fork-Join** (divisi√≥n recursiva de tareas).
  * **MapReduce** (paralelismo distribuido).
  * **Pipelines** y **futuros/promesas**.
* Conceptos avanzados:

  * **Lock-free structures**, **atomics**, **CAS (compare-and-swap)**.
  * **Thread pools** y **work stealing** (asignaci√≥n din√°mica de hilos).

---

## Dise√±o y arquitectura orientada a cambios

### Principios SOLID (extensi√≥n de previsi√≥n de cambios)

* **S**ingle Responsibility
* **O**pen/Closed
* **L**iskov Substitution
* **I**nterface Segregation
* **D**ependency Inversion
* Beneficios:

  * Dise√±o modular, mantenible, extensible.
  * Reduce efectos colaterales y acoplamiento.

### Patr√≥n Strategy + Factory

* Combina flexibilidad (Strategy) con control centralizado (Factory).
* Permite seleccionar e instanciar comportamientos din√°micamente.

{% raw %}
```python
class Strategy:
	def execute(self, a, b): pass

class Add(Strategy):
	def execute(self, a, b): return a + b

class Multiply(Strategy):
	def execute(self, a, b): return a * b

class StrategyFactory:
	@staticmethod
	def get_strategy(op):
		return {"add": Add(), "mul": Multiply()}.get(op)

s = StrategyFactory.get_strategy("add")
print(s.execute(3, 4))  # 7
```
{% endraw %}

---

## Arquitectura y patrones de control

* **Inversi√≥n de control (IoC)** ‚Üí separaci√≥n del flujo principal del detalle.
* **Dependency Injection (DI)** ‚Üí facilita la sustituci√≥n de dependencias.
* **AOP (Programaci√≥n orientada a aspectos)** ‚Üí permite a√±adir comportamientos transversales (logs, seguridad) sin modificar c√≥digo principal.
* **Idempotencia** y **side-effects** controlados en sistemas distribuidos y APIs.

---

## Evaluaci√≥n funcional y transformaci√≥n de datos

### Currying y composici√≥n funcional

* **Currying**: convertir una funci√≥n de N par√°metros en una secuencia de funciones unarias.

{% raw %}
```javascript
const add = x => y => x + y;
console.log(add(2)(3)); // 5
```
{% endraw %}

* **Composici√≥n**: combinar funciones para crear pipelines (`f‚àòg(x) = f(g(x))`).
* Beneficios:

  * C√≥digo modular, predecible, testable.

### Evaluaci√≥n perezosa (lazy evaluation)

* C√°lculo diferido hasta que el valor es necesario.
* Reduce consumo de recursos y permite flujos infinitos.
* Ejemplo: generadores en Python (`yield`).

---

## Pilas, colas y NPI

* NPI notacion polaca inversa utiliza **pila (stack)**.
* **Colas**: √∫tiles para BFS o sistemas reactivos.
* Extensiones:

  * **Deque (double-ended queue)** ‚Üí inserci√≥n y eliminaci√≥n en ambos extremos.
  * **Priority Queue / Heap** ‚Üí prioriza elementos seg√∫n peso o coste.

---

## Conceptos de seguridad y consistencia en algoritmos

* **Idempotencia** ‚Üí estabilidad frente a repetici√≥n.
* **Atomicidad** ‚Üí operaciones indivisibles (importante en concurrencia).
* **Determinismo** ‚Üí misma entrada = mismo resultado (clave para reproducibilidad).
* **Consistencia eventual** ‚Üí sistemas distribuidos que convergen con el tiempo (en contraste con consistencia fuerte).

---

## Tendencias actuales y paradigmas emergentes

* **Algoritmos probabil√≠sticos**:

  * Sacrifican exactitud por eficiencia (ej. Bloom filters, Monte Carlo).
* **Metaheur√≠sticas**:

  * Algoritmos gen√©ticos, recocido simulado, enjambre de part√≠culas.
* **Aprendizaje autom√°tico como optimizaci√≥n**:

  * Muchos modelos usan descenso de gradiente como algoritmo base.
* **Quantum algorithms**:

  * Grover (b√∫squeda O(‚àön)), Shor (factorizaci√≥n en tiempo polin√≥mico).

---

## Conclusi√≥n

Esta nota ampl√≠a el panorama desde fundamentos (ordenaci√≥n, b√∫squeda, recursi√≥n) hasta patrones avanzados (composici√≥n, DI, concurrencia, metaheur√≠sticas).
Integra conceptos de rendimiento, dise√±o, optimizaci√≥n y arquitectura para formar una visi√≥n completa de las **t√©cnicas algor√≠tmicas y computacionales modernas**.

# algoritmos y tecnicas de computacion (expansi√≥n complementaria)

## Paradigmas de programaci√≥n y su relaci√≥n con los algoritmos
- **Imperativo**: describe *c√≥mo* ejecutar paso a paso (C, Python).
- **Declarativo**: describe *qu√©* lograr (SQL, Prolog, Haskell).
- **Funcional**: evita efectos secundarios, promueve pureza e inmutabilidad.
- **Orientado a objetos**: organiza en clases e instancias, basada en abstracci√≥n y encapsulaci√≥n.
- **Reactivo**: modela flujos de datos as√≠ncronos y propagaci√≥n de cambios (Rx, Streams).
- **L√≥gico**: basada en reglas y predicados (backtracking autom√°tico).
- Relaci√≥n con algoritmos:
	- Paradigma condiciona **c√≥mo se expresan y optimizan** los algoritmos.
	- Ej: Dijkstra en funcional ‚Üí recursion + listas inmutables; en imperativo ‚Üí estructuras mutables + bucles.

---

## T√©cnicas de optimizaci√≥n de algoritmos
- **Memoizaci√≥n avanzada**:
	- Uso de decoradores o tablas hash para cachear resultados costosos.
- **Poda heur√≠stica**:
	- Aplicada en backtracking o b√∫squeda A*, evita explorar ramas improbables.
- **Dividir y conquistar (Divide & Conquer)**:
	- Fragmenta el problema ‚Üí resuelve subproblemas ‚Üí combina soluciones.
	- Ej: MergeSort, QuickSort, FFT.
- **Dynamic pruning**:
	- En aprendizaje autom√°tico o IA, descarta rutas con baja ganancia.
- **Optimizaci√≥n incremental**:
	- Evitar recomputaciones totales ante peque√±as variaciones en la entrada (ej. algoritmos de streaming).

---

## T√©cnicas de evaluaci√≥n y pruebas de algoritmos
- **Testing determin√≠stico**:
	- Pruebas reproducibles con entradas fijas.
- **Fuzzing**:
	- Generaci√≥n autom√°tica de inputs aleatorios para detectar errores.
- **Benchmarking**:
	- Comparaci√≥n emp√≠rica entre algoritmos con datasets reales.
- **Profiling**:
	- An√°lisis de tiempo, CPU y memoria por funci√≥n.
- **Test de regresi√≥n algor√≠tmica**:
	- Asegura que las optimizaciones no alteran el resultado esperado.
- Herramientas:
	- Python: `timeit`, `cProfile`, `pytest-benchmark`.
	- C/C++: `gprof`, `perf`, `valgrind`.

---

## Estructuras de datos avanzadas y sus implicaciones algor√≠tmicas
- **√Årboles autoequilibrados**:
	- AVL, Red-Black Tree, B-Tree.
	- Mantienen equilibrio O(log n) en b√∫squeda e inserci√≥n.
- **Tries (prefix trees)**:
	- Para b√∫squedas de cadenas o autocompletado.
- **Segment Trees / Fenwick Trees**:
	- Operaciones por rango (sumas, m√≠nimos) en O(log n).
- **Disjoint Set (Union-Find)**:
	- Detecci√≥n de componentes conectadas (usado en Kruskal).
- **Bloom Filter**:
	- Estructura probabil√≠stica: espacio reducido, falsos positivos posibles.
- **Graph embeddings**:
	- Representaciones vectoriales de grafos para aprendizaje o predicci√≥n.

---

## Paradigmas de resoluci√≥n de problemas
- **Greedy (voraces)**:
	- Toman decisiones locales √≥ptimas esperando resultado global √≥ptimo.
	- Ej: Huffman, Kruskal, Dijkstra.
- **Divide and Conquer**:
	- Resuelve recursivamente dividiendo en subproblemas.
- **Dynamic Programming**:
	- Reutiliza soluciones a subproblemas.
- **Backtracking / Branch & Bound**:
	- Explora soluciones combinatorias.
- **Heur√≠sticas y metaheur√≠sticas**:
	- Aproximaciones cuando el coste exacto es demasiado alto.
	- Ej: recocido simulado, algoritmos gen√©ticos, b√∫squeda tab√∫.
- **Algoritmos estoc√°sticos**:
	- Incorporan aleatoriedad controlada (Monte Carlo, Las Vegas).

---

## Algoritmos distribuidos y consistencia
- **Modelos de comunicaci√≥n**:
	- Mensajer√≠a as√≠ncrona (colas, topics).
	- Memoria compartida distribuida.
- **Algoritmos de consenso**:
	- Paxos, Raft, 2PC, 3PC (Two/Three-Phase Commit).
	- Garantizan consistencia entre nodos.
- **Relojes l√≥gicos**:
	- Lamport y Vector clocks ‚Üí orden parcial de eventos.
- **Compensaciones (Sagas)**:
	- Mecanismos de rollback en transacciones distribuidas.
- **Replicaci√≥n e idempotencia**:
	- Reintentos seguros frente a fallos de red.
- **Patrones de consistencia eventual**:
	- CRDTs, gossip protocols, leader election.

---

## An√°lisis de grafos avanzado
- **Centralidad y m√©tricas estructurales**:
	- Grado, intermediaci√≥n (betweenness), cercan√≠a.
- **Flujos m√°ximos y cortes m√≠nimos**:
	- Ford-Fulkerson, Edmonds-Karp.
- **Matching y cubrimientos**:
	- Emparejamientos bipartitos, algoritmos de Hopcroft-Karp.
- **Algoritmos espectrales**:
	- Basados en descomposici√≥n de matrices de adyacencia o Laplacianas.
- **Detecci√≥n de comunidades**:
	- Modularity maximization, Girvan‚ÄìNewman.
- Aplicaciones:
	- Redes sociales, biolog√≠a computacional, sistemas de recomendaci√≥n.

---

## Teor√≠a de aut√≥matas y algoritmos formales
- **Aut√≥matas finitos**:
	- Deterministas (DFA) y no deterministas (NFA).
	- Base de [Expresiones regulares](/computer%20science/expresiones-regulares/).
- **Aut√≥matas de pila (PDA)**:
	- Para lenguajes libres de contexto (parsers).
- **M√°quinas de Turing**:
	- Modelo general de c√≥mputo; base de la teor√≠a de complejidad.
- **Gram√°ticas formales (Chomsky)**:
	- Tipo 0‚Äì3 ‚Üí jerarqu√≠a de potencia expresiva.
- **Lenguajes decidibles vs indecidibles**:
	- Ejemplo: problema de la parada (Halting Problem).

---

## Complejidad computacional y teor√≠a de clases
- **P, NP, NP-completo, NP-hard**:
	- Clasificaci√≥n seg√∫n tiempo de resoluci√≥n y verificaci√≥n.
- **Reducciones polin√≥micas**:
	- Transformar un problema en otro para probar su dificultad.
- **Problemas cl√°sicos NP**:
	- SAT, viajante, clique, subset-sum.
- **Aproximaci√≥n**:
	- Algoritmos que garantizan soluciones cercanas al √≥ptimo en tiempo polin√≥mico.
- **Randomized algorithms**:
	- Reducen complejidad esperada mediante aleatoriedad (QuickSelect, Bloom filters).

---

## Algoritmos en inteligencia artificial
- **B√∫squeda informada**:
	- A*, IDA*, Greedy Best-First.
- **Optimizaci√≥n evolutiva**:
	- Algoritmos gen√©ticos, mem√©ticos, de enjambre.
- **Aprendizaje por refuerzo**:
	- Q-Learning, SARSA ‚Üí balance entre exploraci√≥n/explotaci√≥n.
- **Redes neuronales**:
	- Entrenamiento basado en backpropagation (descenso de gradiente).
- **Algoritmos de clustering y clasificaci√≥n**:
	- K-Means, DBSCAN, Decision Trees.
- **Teor√≠a de juegos algor√≠tmica**:
	- Equilibrio de Nash, subasta de Vickrey, estrategias adaptativas.

---

## Algoritmos cu√°nticos
- **Principios**:
	- Superposici√≥n y entrelazamiento.
- **Grover**:
	- B√∫squeda en O(‚àön).
- **Shor**:
	- Factorizaci√≥n de enteros en tiempo polin√≥mico.
- **Quantum Fourier Transform (QFT)**:
	- Base de muchos algoritmos cu√°nticos.
- **Limitaciones actuales**:
	- Decoherencia, ruido cu√°ntico, tama√±o de qubits.
- Aplicaciones futuras:
	- Criptograf√≠a post-cu√°ntica, simulaci√≥n molecular, optimizaci√≥n.

---

## Criptograf√≠a y algoritmos de seguridad
- **Criptograf√≠a sim√©trica**: AES, DES ‚Üí misma clave para cifrar/descifrar.
- **Criptograf√≠a asim√©trica**: RSA, ECC ‚Üí par de claves p√∫blica/privada.
- **Hashing criptogr√°fico**: SHA, BLAKE, Argon2 ‚Üí inmutabilidad de datos.
- **Firmas digitales**:
	- Garantizan autenticidad y no repudio.
- **Pruebas de conocimiento cero (ZKP)**:
	- Demostrar que algo es cierto sin revelar la informaci√≥n.
- **Cifrado homom√≥rfico**:
	- Permite operar sobre datos cifrados sin desencriptar.

---

## Algoritmos en sistemas y redes
- **Algoritmos de planificaci√≥n de CPU**:
	- Round Robin, SJF, Prioridades.
- **Gesti√≥n de memoria**:
	- FIFO, LRU, LFU.
- **Ruteo en redes**:
	- Dijkstra, Bellman-Ford, OSPF, BGP.
- **Compresi√≥n de datos**:
	- Huffman, LZ77, Arithmetic Coding.
- **Sistemas de archivos y estructuras persistentes**:
	- B+ Trees, Log-Structured Merge Trees (LSM).

---

## Visualizaci√≥n, geometr√≠a y gr√°ficos computacionales
- **Algoritmos geom√©tricos**:
	- Convex Hull (Graham, Jarvis).
	- Intersecci√≥n de segmentos.
- **Rasterizaci√≥n y renderizado**:
	- Bresenham, Ray tracing.
- **Compresi√≥n de im√°genes y se√±ales**:
	- DCT, Wavelets, Fourier.
- **Simulaci√≥n f√≠sica y optimizaci√≥n**:
	- Verlet integration, RK4, colisiones.
- **Computaci√≥n visual e IA gr√°fica**:
	- Algoritmos de segmentaci√≥n, detecci√≥n de bordes, flujo √≥ptico.

---

## Conclusi√≥n
Esta expansi√≥n complementaria cubre √°mbitos **formales, distribuidos, probabil√≠sticos, de IA y de sistemas**, ampliando los enfoques algor√≠tmicos hacia paradigmas modernos (cu√°ntico, reactivo, evolutivo, criptogr√°fico).  
Integra teor√≠a, pr√°ctica y arquitectura, completando un panorama **total y transversal de la computaci√≥n algor√≠tmica contempor√°nea**.

