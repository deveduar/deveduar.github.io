---
date: 2025-11-19 16:56
title: OpenTelemetry
tags:
keywords:
source:
status: üåü
Parent: "[[Area-Sistemas]]"
cssclasses:
public_note: "true"
category: monitoreo
categories:
  - monitoreo
  - telemetry
  - open_telemetry
  - hide-embedded-header1
---
# OpenTelemetry
`$= dv.current().file.tags.join(" ")`
- [monitoreo](/uncategorized/monitoreo/)
- [Docker](/software%20engineering/docker/)

- [OpenTelemetry](https://opentelemetry.io/)
- [What is OpenTelemetry? | OpenTelemetry](https://opentelemetry.io/docs/what-is-opentelemetry/)
- [Docker deployment | OpenTelemetry](https://opentelemetry.io/docs/demo/docker-deployment/)

OpenTelemetry es un **est√°ndar abierto** para la generaci√≥n, recolecci√≥n, procesamiento y exportaci√≥n de telemetr√≠a (m√©tricas, trazas y logs). Unifica el ecosistema de observabilidad proporcionando APIs, SDKs, agentes y un Collector capaz de trabajar con m√∫ltiples protocolos y backends.

Su objetivo principal es **eliminar la dependencia del proveedor**, simplificar la observabilidad y adoptar un modelo consistente para aplicaciones distribuidas (microservicios, contenedores, serverless, etc.).

---

## Conceptos Fundamentales de OpenTelemetry

### *Signals* de Telemetr√≠a
OpenTelemetry trabaja con tres tipos principales de se√±ales:

- **Trazas (Traces)**  
	Representan el recorrido de una petici√≥n a trav√©s de varios servicios.  
	- Span: unidad m√≠nima de una traza.  
	- Trace ID: correlaci√≥n completa de la solicitud.

- **M√©tricas (Metrics)**  
	Valores num√©ricos y agregables para medir estado del sistema.  
	Ej.: latencia, uso de CPU, throughput.

- **Logs**  
	Registros semiestructurados con contexto adicional, integrados ahora en el pipeline est√°ndar del Collector.

### Componentes Clave

- **APIs y SDKs**  
	Incorporados en tu aplicaci√≥n para instrumentar c√≥digo en lenguajes como Java, Go, Python, JS, .NET, Rust, PHP, etc.

- **Auto-Instrumentaci√≥n**  
	Inserta autom√°ticamente spans, m√©tricas y logs sin modificar c√≥digo (cuando el lenguaje lo soporta).

- **OpenTelemetry Collector**  
	Un servicio altamente configurable que:
	- Recibe telemetr√≠a.
	- La procesa mediante *pipelines*.
	- La exporta a backends como Jaeger, Prometheus, Grafana Tempo, Loki, Elastic, Datadog, etc.

- **Protocolo OTLP**  
	Formato est√°ndar (HTTP/gRPC) para enviar telemetr√≠a entre servicios y Collector.

---

## Ventajas Clave

- **Neutralidad frente a proveedores**  
	Se integra con cualquier backend de an√°lisis y almacenamiento.

- **Escalabilidad y Flexibilidad**  
	Puede desplegarse como:
	- *Agent*: en cada host/sidecar.
	- *Gateway*: centralizado.
	- H√≠brido.

- **Configuraci√≥n Declarativa**  
	Pipelines que permiten:
	- Filtraci√≥n  
	- Enriquecimiento con atributos  
	- Transformaciones con Processors  
	- Sampling avanzado  

- **Estandarizaci√≥n del Ecosistema**  
	Reducci√≥n del acoplamiento con agentes propietarios.

---

## Arquitectura General

Servicio ‚Üí SDK/Auto-Inst ‚Üí Collector ‚Üí Procesamiento ‚Üí Backend

- Las aplicaciones generan telemetr√≠a.
- El Collector unifica toda la gesti√≥n.
- La exportaci√≥n es modular y reemplazable sin cambiar el c√≥digo de la aplicaci√≥n.

---

## Proceso Completo de Gesti√≥n de Logs con OpenTelemetry

La gesti√≥n de logs con OTel se integra en un *pipeline unificado* junto con m√©tricas y trazas.

1. **Instrumentaci√≥n y Recolecci√≥n**
	- SDKs o auto-instrumentaci√≥n generan logs con contexto de trazas (trace_id, span_id).
	- Receivers del Collector aceptan logs desde:
		- OTLP
		- FluentBit / Fluentd
		- Syslog
		- Filelog receiver (lectura directa de archivos)

2. **Centralizaci√≥n e Indexaci√≥n**
	- El Collector consolida todos los logs.
	- Permite normalizaci√≥n previa a enviarlos a backends como:
		- Loki
		- Elastic
		- Splunk
		- ClickHouse
		- S3 (archiving)

3. **Procesamiento y An√°lisis**
	- **Transform Processor** para enriquecer entradas.
	- **Attribute Processor** para limpiar/renombrar.
	- **Groupby / batch / filter** para control de volumen.
	- **Correlation**: une traces ‚Üî logs ‚Üî m√©tricas.

4. **Monitoreo y Alertas**
	- Los logs se visualizan y correlacionan con dashboards y reglas de alerta externas.

5. **Dashboards**
	- Dashboards en Grafana, Kibana u otros backends.
	- Integraci√≥n nativa con Prometheus para m√©tricas.

---

## Despliegue de OpenTelemetry con Docker

Desplegar el Collector con Docker proporciona un entorno reproducible y portable.

---

## Ejemplo de Configuraci√≥n del Collector

Crear un archivo `otel-collector-config.yaml`:

{% raw %}
```yaml
receivers:
	otlp:
		protocols:
			grpc:
			http:
	filelog:
		include: ["/var/log/*.log"]
		start_at: beginning

processors:
	batch:
		timeout: 5s
		transient_error_removal: true
	attributes:
		actions:
			- key: service.environment
				value: "production"
				action: upsert
	resource:
		attributes:
			- key: host.name
				action: insert
	transform:
		log_statements:
			- context: log
				statements:
					- replace(match(attributes["level"], "warn"), attributes["level"], "warning")

exporters:
	logging:
		loglevel: debug
	prometheus:
		endpoint: "0.0.0.0:8889"
	otlphttp:
		endpoint: "http://localhost:4318"

service:
	pipelines:
		traces:
			receivers: [otlp]
			processors: [batch]
			exporters: [logging]
		metrics:
			receivers: [otlp]
			processors: [batch]
			exporters: [prometheus]
		logs:
			receivers: [otlp, filelog]
			processors: [batch, attributes, transform]
			exporters: [logging]
```
{% endraw %}`

---

## Ejecutar el Collector con Docker

{% raw %}
```bash
docker run -p 4317:4317 -p 4318:4318 -p 8889:8889 \
	-v $(pwd)/otel-collector-config.yaml:/etc/otel/config.yaml \
	otel/opentelemetry-collector:latest \
	--config=/etc/otel/config.yaml
```
{% endraw %}

---

## Docker Compose (Collector + Sistema Extensible)

Archivo `docker-compose.yml`:

{% raw %}
```yaml
version: '3'
services:
	otel-collector:
		image: otel/opentelemetry-collector:latest
		container_name: otel-collector
		volumes:
			- ./otel-collector-config.yaml:/etc/otel/config.yaml
		command: ["--config=/etc/otel/config.yaml"]
		ports:
			- "4317:4317"   # OTLP gRPC
			- "4318:4318"   # OTLP HTTP
			- "8889:8889"   # Prometheus exporter

	jaeger:
		image: jaegertracing/all-in-one
		ports:
			- "16686:16686"
			- "14250:14250"
```
{% endraw %}

Lanzar los servicios:

{% raw %}
```bash
docker compose up -d
```
{% endraw %}

---

## Casos de Uso Relevantes

- Observabilidad completa de **microservicios**.
- Monitoreo para **entornos Kubernetes** mediante auto-instrumentaci√≥n y agentes.
- Obtenci√≥n de telemetr√≠a para **API Gateways**, **Service Mesh** (Istio/Envoy), Sidecars.
- Uso en pipelines de seguridad (detecci√≥n de outliers mediante logs).
- Unificaci√≥n de telemetr√≠a en sistemas multi-backend.

---

## Buenas Pr√°cticas

- Usar OTLP siempre que sea posible (est√°ndar moderno).
- Mantener Collector separado del plano de aplicaci√≥n.
- Aplicar _sampling_ avanzado para reducir costos en traces.
- Versionar los pipelines del Collector.
- A√±adir atributos consistentes (service.name, env, version).

---

# Pr√°cticas Recomendadas para Pipelines de OpenTelemetry Collector

## Introducci√≥n
Esta nota recopila pr√°cticas recomendadas para dise√±ar pipelines s√≥lidos en el **OpenTelemetry Collector**, asegurando recolecci√≥n confiable, escalabilidad global, gobernanza del flujo de datos y compatibilidad en arquitecturas complejas (service mesh, multi-regi√≥n, multi-nube y despliegues progresivos).

Los pipelines siguen la estructura:
{% raw %}
```

receivers ‚Üí processors ‚Üí exporters

```
{% endraw %}

---

## Principios Generales de Dise√±o
- Pipelines cortos y especializados (evitar pipelines "todo en uno").
- Separar **pipelines por tipo de se√±al**: logs, m√©tricas, traces.
- Mantener configuraciones modulares usando `include`, `yaml anchors` o toolings.
- Minimizar parsers complejos en el Collector (hacerlo antes si es posible).
- Estrategia de **redudancia**: al menos 2 collectors por zona/region.
- Dise√±ar con **backpressure awareness** (cola, batch, memory_limiter).

---

## Receivers: Buenas Pr√°cticas
### Configuraci√≥n recomendada
- Usar OTLP gRPC como protocolo principal (m√°s eficiente que HTTP).
- Habilitar TLS siempre que sea posible.
- Mantener puertos dedicados por se√±al.
- Evitar receptores experimentales en producci√≥n.

### Recomendaciones clave
- Separar receivers por servicio/entorno (dev/stage/prod).
- En service mesh, usar sidecar o gateway (ingesti√≥n por agente local).
- Para logs, preferir receivers nativos (filelog, journald, docker).

---

## Processors: Pr√°cticas Recomendadas
Los processors son el coraz√≥n del pipeline. Las pr√°cticas m√°s importantes:

### Processors esenciales a incluir
- `batch`: casi obligatorio en producci√≥n.
- `memory_limiter`: evitar OOM y ca√≠das.
- `attributes`: enmascarar datos sensibles.
- `resource`: a√±adir metadata (cluster, regi√≥n, servicio).
- `filter`: para higiene y eliminaci√≥n de ruido.
- `transform`: normalizaci√≥n avanzada (OTTL).

### Orden recomendado
{% raw %}
```

memory_limiter ‚Üí batch ‚Üí transform ‚Üí resource ‚Üí attributes ‚Üí filter

```
{% endraw %}

### Est√°ndares
- Normalizar nombres de servicios antes de exportar.
- Eliminar trazas ruidosas (health checks repetitivos).
- Enriquecer con etiquetas obligatorias:
	- `cloud.region`
	- `k8s.cluster.name`
	- `deployment.environment`
	- `service.version`

---

## Exporters: Buenas Pr√°cticas
### Reglas generales
- Exportar a m√∫ltiples backends s√≥lo mediante **pipelines separados** (no mezclar).
- Evitar exporters que carezcan de capacidades de reintento.
- Usar OTLP como formato est√°ndar hacia data-lakes o collectors centrales.

### Patrones de exportaci√≥n
- Local ‚Üí Gateway ‚Üí Backend
- Local ‚Üí Gateway ‚Üí Enriquecimiento ‚Üí Multiples destinos
- Multi-regi√≥n con failover autom√°tico (OTLP multi-endpoint)

### Exporters recomendados
- OTLP exporter (est√°ndar)
- Prometheus exporter (para m√©tricas)
- Loki export v√≠a gateway intermedio
- Kafka exporter para arquitecturas streaming-first

---

## Pipelines en Service Mesh (Istio/Linkerd)
### Recomendaciones
- Recibir telemetr√≠a directamente desde sidecars.
- Filtrar tr√°fico interno no relevante (pings, probes).
- Enriquecer con etiquetas del mesh:
	- `mesh.traffic.direction`
	- `mesh.source_workload`
	- `mesh.destination_workload`

### Procesamiento est√°ndar
- Normalizar trazas duplicadas generadas por sidecars.
- Correlaci√≥n autom√°tica entre spans de mesh y spans de app.

---

## Pipelines Multi-Regi√≥n / Multi-Cluster
### Arquitectura recomendada
{% raw %}
```

Agente Local (Pod/VM)
‚Üí Collector Regional
‚Üí Collector Global
‚Üí Backend(s)

```
{% endraw %}`

### Buenas pr√°cticas
- Exportaci√≥n regional ‚Üí corte por regi√≥n, no global.
- Enriquecer con `cloud.region`, `k8s.cluster.name`.
- Rollouts graduales de pipelines:
	1. Regi√≥n secundaria
	2. Regi√≥n menos cr√≠tica
	3. Regi√≥n principal

### Mesh multi-cluster
- Alinear nombres de servicios entre clusters para evitar cardinalidad infinita.
- Normalizar latencias entre clusters.

---

## Pipelines para Canary Releases
### Objetivos
- Observar versiones canary vs stable en paralelo.
- Validar latencia, errores y throughput por versi√≥n.

### Pr√°cticas recomendadas
- A√±adir atributo `service.version` o `deployment.version`.
- Filtrado avanzado por versi√≥n usando OTTL:
	{% raw %}
```yaml
	processors:
		filter/canary:
			traces:
				include:
					match_type: strict
					attributes:
						service.version: "canary"
	```
{% endraw %}

- Exportadores distintos:
	- Canary ‚Üí backend temporal
	- Estable ‚Üí backend principal

- Activar comparaci√≥n autom√°tica en dashboards.

---

## Pipelines con Enriquecimiento Avanzado (OTTL)
### Casos de uso
- Reducci√≥n de cardinalidad en m√©tricas.
- Limpieza de logs sensibles.
- Reglas para mover atributos entre signals.

### Ejemplo de regla OTTL
{% raw %}
```yaml
- set(attributes["http.method"], "REDACTED") where attributes["http.method"] == "TRACE"
```
{% endraw %}`

---

## Gobernanza y Control de Calidad del Pipeline

### Pr√°cticas esenciales

* Versionar configuraciones del Collector como IaC.
* Tests automatizados de configuraci√≥n (Conftest, OPA).
* Validaciones de schema OTEL v√≠a CI.
* No aplicar nuevas reglas sin:

  1. Canary interno del Collector
  2. M√©tricas de fallback
  3. Pruebas de compatibilidad

### Monitorizar el Collector mismo

* CPU, memoria, dropped spans/logs/metrics.
* Export failures.
* Queue length.
* Latencias internas.

---

## Seguridad

* TLS obligatorio entre agentes y collectors.
* Firmar binarios del collector.
* Sanitizar logs autom√°ticamente:

  * Tokens
  * Emails
  * IPs sensibles
* Aislar collectors por funci√≥n:

  * Ingesti√≥n
  * Procesamiento pesado
  * Exportaci√≥n

---

## Ejemplos de Arquitecturas Recomendadas

### 1. Pipeline Complejo Est√°ndar

{% raw %}
```
Agent (host/app)
	‚Üí Collector Local
		‚Üí Processor: batch, attributes, transform
	‚Üí Collector Global
		‚Üí Exporters: Prometheus, Jaeger, Loki, Kafka
```
{% endraw %}

### 2. Service Mesh + Multi-Cluster

{% raw %}
```
Sidecars Istio
	‚Üí Node Agent
	‚Üí Cluster Collector
	‚Üí Global Collector
```
{% endraw %}

### 3. Canary vs Stable

{% raw %}
```
Local Collector
	‚Üí Pipeline A (stable)
	‚Üí Pipeline B (canary)
	‚Üí Backends separados
```
{% endraw %}

---

## Checklist Final de Mejores Pr√°cticas

1. Separar pipelines por se√±al.
2. Always-on processors: `memory_limiter` + `batch`.
3. Normalizaci√≥n estricta de recursos.
4. Filtrar ruido (health checks, tr√°ficos internos).
5. Exportar con OTLP siempre que sea posible.
6. Multi-regi√≥n escalonado.
7. Pipelines paralelos para canary.
8. Validar collectors con tests y canaries.
9. Monitorear el propio collector.
10. Documentar el flujo completo (Mermaid).

# OpenTelemetry ‚Äî Conceptos Avanzados y Arquitectura Profunda

## Modelo de Arquitectura Avanzada

OpenTelemetry proporciona distintos patrones de despliegue seg√∫n el tipo de carga, topolog√≠a y madurez de la observabilidad. Estos patrones se combinan para asegurar resiliencia y minimizar el acoplamiento.

### Patrones de Despliegue

- **Collector como Gateway √önico**
	- Todos los servicios env√≠an telemetr√≠a a un Collector central.
	- Ideal para entornos con control de latencia y un solo dominio de red.

- **Collector como Sidecar**
	- Un Collector por servicio o pod.
	- Garantiza aislamiento, reduce overhead en la aplicaci√≥n y permite procesar localmente.

- **Collector por Nodo (Node Agent)**
	- Muy com√∫n en Kubernetes.
	- Ideal para recolectar m√©tricas del host, logs de nodos y telemetr√≠a de contenedores.

- **H√≠brido**
	- Combinaci√≥n de sidecars + gateway centralizado.
	- Da resiliencia y reducci√≥n de cargas hacia el backend.

---

## OpenTelemetry y Service Mesh

Service Mesh (como **Istio**, **Linkerd**, **Consul**) transforma la forma de generar telemetr√≠a:

- Los proxies (Envoy) generan:
	- M√©tricas (latencia, errores, throughput)
	- Spans autom√°ticos de solicitudes entre servicios
	- Logs de acceso enriquecidos

- OpenTelemetry integra directamente con Envoy via:
	- **OTLP Access Log Service**
	- **HTTP/gRPC tracing service**
	- **In-band context propagation**

### Beneficios

- Correlaci√≥n autom√°tica entre tr√°fico L7 y servicios upstream/downstream.
- Eliminaci√≥n de instrumentaci√≥n manual en muchas rutas.
- Observabilidad ‚Äúzero-touch‚Äù.

---

## Context Propagation

La propagaci√≥n de contexto evita ‚Äútrazas partidas‚Äù.  
OpenTelemetry implementa **W3C TraceContext**, **Baggage** y formatos heredados.

Tipos de contexto:

1. **Trace Context**  
	Propaga `trace_id`, `span_id`, `trace_flags`.

2. **Baggage**  
	Atributos arbitrarios que viajan por todas las capas:  
	ej. `user_id`, `tenant`, `region`.

3. **Custom Propagators**
	- Se usan para compatibilidad con sistemas legados.
	- Pueden transformar o a√±adir metadata para correlaci√≥n.

---

## Sampling Avanzado

OpenTelemetry incluye modelos flexibles para controlar el volumen de trazas.

### Estrategias de Sampling

- **Always On**  
	100% de las trazas. √ötil en entornos de desarrollo.

- **Always Off**  
	No captura spans excepto manuales.

- **TraceIDRatioBased**
	Captura un porcentaje configurable.

- **ParentBased**
	Hereda la decisi√≥n del span padre.

- **Tail Sampling (Collector)**  
	El m√°s poderoso:
	- Permite seleccionar trazas basadas en atributos.
	- Ejemplo:
		- Errores 100%.
		- Latencias >500ms.
		- Usuarios premium.

Se ejecuta en el Collector (no en los SDK), permitiendo decisiones basadas en la traza completa.

---

## Procesadores Avanzados

Adem√°s del *batch processor*, existen procesadores m√°s espec√≠ficos:

- **tailsampling processor**
	- Decide qu√© trazas conservar.

- **filter processor**
	- Permite incluir/excluir telemetr√≠a seg√∫n reglas.

- **resourcedetection processor**
	- Detecta autom√°ticamente informaci√≥n de:
		- Kubernetes
		- AWS / GCP / Azure
		- Host
		- VM metadata

- **routing processor**
	- Env√≠a distintos pipelines a diferentes exportadores.
	- Ejemplo: m√©tricas ‚Üí Prometheus, trazas ‚Üí Tempo, logs ‚Üí Loki.

---

## Exporters y Backends Compatibles

OpenTelemetry soporta una amplia gama de destinos:

### Exporters Populares

- **Tempo** (traces)
- **Jaeger**
- **Zipkin**
- **Prometheus**
- **Loki** (logs)
- **Elastic**
- **Kafka** (buffer y recolecci√≥n masiva)
- **S3 / GCS / Azure Blob** (archiving)
- **OTLP exporter** para encadenar m√∫ltiples Collectors

### Exporters Empresariales

- Datadog
- New Relic
- Dynatrace
- Lightstep
- Splunk
- Honeycomb
- AppDynamics

---

## Receivers Especializados

OpenTelemetry Collector puede recibir telemetr√≠a desde m√∫ltiples fuentes:

- **hostmetrics receiver**
	- CPU, memoria, filesystem, network, loadavg.
- **kubeletstats receiver**
	- M√©tricas de pods y containers.
- **journald receiver**
	- Logs de sistemas Linux.
- **syslog receiver**
- **filelog receiver**
- **prometheus receiver**
	- Act√∫a como un Prometheus server parcial.
- **tail sampling receiver**
	- Ingresa trazas de sampling avanzado.

---

## Instrumentaci√≥n Autom√°tica (Auto-Instrumentation)

Disponible en:

- **Java Agent**
- **Node.js**
- **Python**
- **.NET**
- **Go (con wrappers)**
- **Ruby**
- **PHP**
- **Rust (en evoluci√≥n)**

### Ventajas

- No requiere modificar c√≥digo.
- Inserta spans en:
	- HTTP servers/clients  
	- DB drivers  
	- ORMs  
	- MQ (Kafka, RabbitMQ)  
	- Frameworks web  

---

## OpenTelemetry en Kubernetes: Recolecci√≥n Completa

Patr√≥n t√≠pico:

- Collector modo **DaemonSet**
	- Recepci√≥n de:
		- Logs de contenedores via filelog receiver  
		- M√©tricas node/hostmetrics  
		- M√©tricas kubeletstats  
	- Exportaci√≥n a backend

- Collector modo **Deployment**
	- Recibe OTLP de aplicaciones
	- Hace tail sampling
	- Reenv√≠a trazas filtradas

- Sidecar opcional para apps sin SDK nativo

---

## Integraci√≥n con Herramientas CI/CD

- Publicar *service version* como recurso.
- A√±adir atributos como:
	- `deployment.environment`
	- `build.commit`
	- `build.pipeline.id`
- Permite correlaci√≥n entre despliegues y degradaciones.

---

## Observabilidad Unificada

OpenTelemetry permite:

- Correlaci√≥n *logs ‚Üî traces ‚Üî metrics*
- Atribuir m√©tricas a spans
- Insertar logs enriquecidos dentro de spans
- Crear paneles de:
	- errores por ruta  
	- latencias por servicio  
	- anomal√≠as por log pattern  
	- saturaci√≥n de recursos  

---

## Patrones de Dise√±o en Observabilidad

- **RED Metrics** (Rate, Errors, Duration)
- **USE Metrics** (Utilizaci√≥n, Saturaci√≥n, Errores)
- **SLOs basados en trazas**
- **An√°lisis de cuellos de botella con spans jer√°rquicos**

---

## Casos de Uso Avanzados

- Observabilidad para sistemas **event-driven** (Kafka, NATS, RabbitMQ).
- Monitoreo de pipelines ML con trazas de etapas.
- Trazabilidad distribuida en **APIs multi regi√≥n**.
- Recolecci√≥n de logs masivos en entornos edge.
- Telemetr√≠a para sistemas IoT mediante OTLP/HTTP.


# OpenTelemetry ‚Äî Ejemplos de Pipelines Completos

Esta nota recopila pipelines listos para usar en el Collector, cada uno dise√±ado para un caso de uso real distinto. Incluye trazas, m√©tricas y logs, as√≠ como enrutamiento avanzado, transformaciones, sampling y exportaci√≥n a m√∫ltiples backends.

---

## Pipeline 1 ‚Äî Traces + Tail Sampling + Exportaci√≥n M√∫ltiple

{% raw %}
```yaml
receivers:
	otlp:
		protocols:
			http:
			grpc:

processors:
	batch:
	tailsampling:
		policies:
			- name: errors
				type: status_code
				status_code:
					statuses: ["ERROR"]
			- name: high_latency
				type: latency
				latency:
					threshold_ms: 500
			- name: user_premium
				type: string_attribute
				string_attribute:
					key: user.tier
					values: ["premium"]

exporters:
	otlp:
		endpoint: tempo:4317
		tls:
			insecure: true
	logging:
		loglevel: info

service:
	pipelines:
		traces:
			receivers: [otlp]
			processors: [tailsampling, batch]
			exporters: [otlp, logging]
```
{% endraw %}`

**Aporta:**
‚úì Mantiene 100% de errores
‚úì Guarda trazas lentas
‚úì Sampling condicional por atributos
‚úì Exporta simult√°neamente a Tempo y logs

---

## Pipeline 2 ‚Äî Logs desde archivos + Normalizaci√≥n + Loki

{% raw %}
```yaml
receivers:
	filelog:
		include: ["/var/log/app/*.log"]
		start_at: beginning
		operators:
			- type: regex_parser
				regex: '^(?P<ts>[^ ]+) (?P<level>[^ ]+) (?P<msg>.*)$'
				timestamp:
					parse_from: ts
					layout: "%Y-%m-%dT%H:%M:%SZ"

processors:
	filter:
		logs:
			include:
				match_type: regexp
				expressions:
					- 'attributes["level"] == "ERROR"'
	attributes:
		actions:
			- key: level
				action: update
				value: error

exporters:
	loki:
		endpoint: http://loki:3100/loki/api/v1/push

service:
	pipelines:
		logs:
			receivers: [filelog]
			processors: [filter, attributes]
			exporters: [loki]
```
{% endraw %}

**Aporta:**
‚úì Ingresa logs desde archivos
‚úì Aplica parsing con regex
‚úì Solo guarda errores
‚úì Env√≠a a Loki

---

## Pipeline 3 ‚Äî M√©tricas del Host + Node Exporter Replacement

{% raw %}
```yaml
receivers:
	hostmetrics:
		collection_interval: 10s
		scrapers:
			cpu:
			memory:
			filesystem:
			network:
			load:

processors:
	batch:

exporters:
	prometheus:
		endpoint: 0.0.0.0:9090

service:
	pipelines:
		metrics:
			receivers: [hostmetrics]
			processors: [batch]
			exporters: [prometheus]
```
{% endraw %}

**Aporta:**
‚úì Reemplaza a node_exporter
‚úì M√©tricas del sistema
‚úì Exposici√≥n en /metrics

---

## Pipeline 4 ‚Äî Enrutamiento seg√∫n tipo de se√±al ‚Üí (Prometheus, Tempo, Loki)

{% raw %}
```yaml
receivers:
	otlp:
		protocols:
			grpc:
			http:

processors:
	batch:

exporters:
	prometheus:
		endpoint: 0.0.0.0:9000
	otlp_tempo:
		endpoint: tempo:4317
		tls:
			insecure: true
	loki:
		endpoint: http://loki:3100/loki/api/v1/push

service:
	pipelines:
		metrics:
			receivers: [otlp]
			processors: [batch]
			exporters: [prometheus]

		traces:
			receivers: [otlp]
			processors: [batch]
			exporters: [otlp_tempo]

		logs:
			receivers: [otlp]
			processors: [batch]
			exporters: [loki]
```
{% endraw %}

**Aporta:**
‚úì Separaci√≥n por se√±al
‚úì Ideal para Grafana Stack (Tempo + Loki + Prometheus)

---

## Pipeline 5 ‚Äî Kubernetes Logs + Metadata Enrichment

{% raw %}
```yaml
receivers:
	filelog:
		include: ["/var/log/containers/*.log"]
		include_file_path: true
		operators:
			- type: container_parser

processors:
	k8sattributes:
		filter:
			node_from_env_var: K8S_NODE_NAME
	metadata:
		annotations:
			extract: ["team", "project"]
			replace: ["owner"]
	labels:
		extract: ["app", "pod_template_hash"]
	batch:

exporters:
	loki:
		endpoint: http://loki:3100/loki/api/v1/push

service:
	pipelines:
		logs:
			receivers: [filelog]
			processors: [k8sattributes, batch]
			exporters: [loki]
```
{% endraw %}

**Aporta:**
‚úì Recolecta logs de contenedores Kubernetes
‚úì Enrich con metadata del pod
‚úì Team / project / owner
‚úì Exportaci√≥n a Loki

---

## Pipeline 6 ‚Äî M√©tricas Prometheus + Reetiquetado ‚Üí OTLP

{% raw %}
```yaml
receivers:
	prometheus:
		config:
			scrape_configs:
				- job_name: "apps"
					static_configs:
						- targets: ["app1:8080", "app2:8080"]

processors:
	attributes:
		actions:
			- action: insert
				key: environment
				value: staging

exporters:
	otlp:
		endpoint: collector-upstream:4317
		tls:
			insecure: true

service:
	pipelines:
		metrics:
			receivers: [prometheus]
			processors: [attributes]
			exporters: [otlp]
```
{% endraw %}

**Aporta:**
‚úì Collector actuando como mini Prometheus
‚úì Reetiquetado
‚úì Exportaci√≥n v√≠a OTLP

---

## Pipeline 7 ‚Äî Logs + Traces Correlacionados (Insertar TraceID en Logs)

{% raw %}
```yaml
receivers:
	otlp:
		protocols:
			grpc:
			http:

processors:
	resource:
		attributes:
			- key: service.source
				value: "api-gateway"
				action: upsert
	transform:
		log_statements:
			- context: log
				statements:
					- set(attributes["trace_id"], trace_id)
					- set(attributes["span_id"], span_id)

exporters:
	loki:
		endpoint: http://loki:3100/loki/api/v1/push
	otlp:
		endpoint: tempo:4317
		tls:
			insecure: true

service:
	pipelines:
		logs:
			receivers: [otlp]
			processors: [resource, transform]
			exporters: [loki]

		traces:
			receivers: [otlp]
			processors: [resource]
			exporters: [otlp]
```
{% endraw %}

**Aporta:**
‚úì Enriquecimiento autom√°tico
‚úì Inserta trace_id/span_id en logs
‚úì Correlaci√≥n garantizada en Loki + Tempo

---

## Pipeline 8 ‚Äî Kafka como Buffer de Telemetr√≠a

{% raw %}
```yaml
receivers:
	otlp:
		protocols:
			http:
			grpc:

processors:
	batch:

exporters:
	kafka:
		protocol_version: 2.0.0
		brokers: ["kafka:9092"]
		topic: otel-telemetry
		encoding: otlp_json

service:
	pipelines:
		traces:
			receivers: [otlp]
			processors: [batch]
			exporters: [kafka]

		metrics:
			receivers: [otlp]
			processors: [batch]
			exporters: [kafka]

		logs:
			receivers: [otlp]
			processors: [batch]
			exporters: [kafka]
```
{% endraw %}

**Aporta:**
‚úì Buffer masivo
‚úì Ideal para cargas muy altas
‚úì Telemetr√≠a enviada a Kafka para procesadores offline

---

## Pipeline 9 ‚Äî Filtrado Avanzado (Excluir Salud, Incluir Errores 5xx)

{% raw %}
```yaml
receivers:
	otlp:

processors:
	filter:
		traces:
			exclude:
				match_type: regexp
				expressions:
					- 'attributes["http.target"] == "/health"'
		transform:
			trace_statements:
				- context: span
					statements:
						- keep_if(attributes["http.status_code"] >= 500)

exporters:
	logging:
	otlp:
		endpoint: tempo:4317
		tls:
			insecure: true

service:
	pipelines:
		traces:
			receivers: [otlp]
			processors: [filter, transform]
			exporters: [logging, otlp]
```
{% endraw %}

**Aporta:**
‚úì Excluye tr√°fico irrelevante (/health)
‚úì Solo guarda spans 5xx
‚úì Reduce consumo de backend

---

## Pipeline 10 ‚Äî Collector como Router por Atributos (Multi-Tenant)

{% raw %}
```yaml
receivers:
	otlp:
		protocols:
			grpc:

processors:
	routing:
		from_attribute: tenant
		table:
			tenantA: [exporter_a]
			tenantB: [exporter_b]
			default: [exporter_default]

exporters:
	exporter_a:
		endpoint: tempo-a:4317
		tls:
			insecure: true
	exporter_b:
		endpoint: tempo-b:4317
		tls:
			insecure: true
	exporter_default:
		endpoint: tempo-default:4317
		tls:
			insecure: true

service:
	pipelines:
		traces:
			receivers: [otlp]
			processors: [routing]
			exporters: [exporter_default]
```
{% endraw %}

**Aporta:**
‚úì Multi-tenant real
‚úì Routing por atributo
‚úì Ideal para SaaS

# Pipelines CI/CD Avanzados

## Pipeline 1: Despliegue Multi-Regi√≥n + Service Mesh (Istio) + Validaci√≥n Autom√°tica
Pipeline orientado a empresas que despliegan la misma app en varias regiones con control de tr√°fico inteligente.

### Flujo
1. **Trigger**
	- Commit ‚Üí Build incremental optimizado.
2. **Build**
	- Imagen Docker con firma (cosign).
	- SBOM generado (Syft, Trivy).
3. **Tests**
	- Unit ‚Üí Integration ‚Üí Contract tests.
	- e2e simulando regiones (mock de edge routers).
4. **Infra as Code**
	- Terraform plan para `eu-west-1` y `us-east-1`.
	- Validaci√≥n autom√°tica con OPA/Conftest.
5. **Despliegue a Staging**
	- Helm chart aplicado.
	- Inyecci√≥n autom√°tica de sidecars Istio.
6. **Service Mesh Checks**
	- Pruebas de:
		- mTLS
		- Policies
		- VirtualServices / DestinationRules correctas
7. **Shadow Traffic**
	- 5% de tr√°fico real replicado a la nueva versi√≥n sin afectar usuarios.
8. **Despliegue Multi-Regi√≥n**
	- Orden:
		1. Regi√≥n secundaria (`eu-west-1`)
		2. Regi√≥n primaria (`us-east-1`)
	- Cada paso exige health checks de mesh + app.
9. **Rollback autom√°tico**
	- Basado en m√©tricas:
		- p95 latency
		- error_rate
		- 5xx spikes
10. **Notificaci√≥n + Auditor√≠a**
	- Slack + registro en CMDB + firma de artefactos.

### Artefactos Generados
- Imagen versionada y firmada.
- Terraform plan + apply logs.
- Helm release.
- Reporte de observabilidad/m√©tricas.

---

## Pipeline 2: Canary Progressive Delivery con Argo Rollouts + Tracking Inteligente
Pipeline usado para despliegues de alto riesgo donde el canario se eval√∫a por m√©tricas, no por tiempo.

### Flujo
1. **Trigger**
	- PR con revisi√≥n obligatoria.
2. **Build**
	- Docker + an√°lisis est√°tico (Sonar, CodeQL).
3. **Tests avanzados**
	- Mutation testing.
	- API contract verificando backward compatibility.
4. **Deploy Canary con Argo Rollouts**
	- Weight inicial: 1%
	- Pasos autom√°ticos:
		- 1% ‚Üí 5% ‚Üí 25% ‚Üí 50% ‚Üí 100%
		- S√≥lo si:
			- error_rate < 0.5%
			- Latencia p95 < 200ms
			- No hay degradaci√≥n en logs (Loki / ELK)
5. **Canary Tracking Inteligente**
	- ML simple (Z-score) para detectar anomal√≠as.
	- Evaluaci√≥n en tiempo real de usuarios reales.
6. **Experimentos A/B dentro del canario**
	- S√≥lo usuarios chrome ver√°n la nueva feature.
7. **Rollback Autom√°tico**
	- Si hay spike de errores o aumento de latencia:
		- Rollback inmediato.
		- Cierre del rollout + alerta a equipo.
8. **Promoci√≥n**
	- Argo marca el despliegue como ‚ÄúStable‚Äù.
	- Kubernetes actualiza todos los replicasets.

### Integraciones
- Argo Rollouts
- Prometheus/Grafana para m√©tricas
- Loki para logs
- OPA para pol√≠ticas
- Sentry para errores

---

## Pipeline 3: Microservicios con Service Mesh + Testing de Resiliencia + Chaos Engineering
Modelo empresarial orientado a resiliencia en tiempo real.

### Flujo
1. **Build por servicio**
	- Cada servicio genera su propio artefacto.
	- Build caching + Reproducible builds.
2. **Tests**
	- Unitarios
	- Contract (Pact)
	- e2e distribuidos simulando fallos de red
3. **Despliegue a entorno Mesh**
	- Inyecci√≥n de sidecar Envoy.
	- Configuraci√≥n autom√°tica de:
		- Retries
		- Timeouts
		- Circuit Breakers
4. **Chaos Tests Autom√°ticos**
	- Escenario:
		- Matar pods aleatorios.
		- Inject latency 200ms.
		- Drop 10% de paquetes.
5. **Validaci√≥n de Resiliencia**
	- Golden signals deben mantenerse:
		- Latency
		- Traffic
		- Errors
		- Saturation
6. **Promoci√≥n**
	- Si resiliencia ‚â• threshold, se publica.
7. **Rollback**
	- Si resiliencia se degrada, rollback inmediato.

---

## Pipeline 4: Multi-Cloud Activo/Activo con Replicaci√≥n de Datos
Despliega en AWS + GCP simult√°neamente.

### Flujo
1. **Build y firma**
	- Docker + cosign.
2. **Terraform Multi-Cloud**
	- AWS:
		- EKS
		- RDS
	- GCP:
		- GKE
		- CloudSQL
3. **Sincronizaci√≥n de Datos**
	- CDC (Change Data Capture) con Debezium.
	- Replicaci√≥n entre nubes.
4. **Despliegue Blue/Green**
	- En ambas nubes.
5. **Routing Global**
	- Cloudflare / Traffic Director:
		- 50% tr√°fico AWS
		- 50% tr√°fico GCP
6. **Failover Autom√°tico**
	- Si un proveedor cae:
		- Todo el tr√°fico se redirige a la otra nube.
7. **Promoci√≥n**
	- Se sincroniza la versi√≥n ‚Äúgreen‚Äù como master.

---

## Pipeline 5: Infraestructuras Regulatorias con Auditor√≠a y Gates de Seguridad
Dise√±ado para entornos fintech/health.

### Flujo
1. **Build**
	- Imagen Docker escaneada (Clair/Trivy).
	- Comprobaci√≥n SBOM obligatoria.
2. **Tests**
	- Unit ‚Üí Integration ‚Üí Compliance tests.
3. **Security Gates**
	- CodeQL
	- SAST
	- DAST
	- OPA para pol√≠ticas de infraestructura
	- Comprobaciones de secreto (git-secrets)
4. **Infra as Code**
	- Terraform + Sentinel (pol√≠ticas obligatorias)
5. **Despliegue a Entorno Aislado**
	- Zero-trust networking.
	- Service mesh mTLS obligatorio.
6. **Aprobaci√≥n Manual (Dual Approval)**
	- Dos personas distintas deben aprobar.
7. **Despliegue controlado**
	- Blue/Green
	- Validaci√≥n con test automatizados post-deploy
8. **Auditor√≠a**
	- Registro inmutable (Loki / Elasticsearch / AWS AuditLogs).

# Pr√°cticas Recomendadas para Pipelines CI/CD

## Introducci√≥n
Esta nota resume un conjunto de **buenas pr√°cticas avanzadas** para dise√±ar, implementar y gestionar pipelines CI/CD robustos, auditables y altamente escalables. Est√° orientada a entornos modernos con contenedores, orquestadores, IaC, service mesh, multi-regi√≥n y despliegues progresivos.

---

## Dise√±o General del Pipeline
Un pipeline debe ser **modular, declarativo, idempotente** y **observable**. Cada etapa debe aportar valor, validar calidad o asegurar consistencia entre cambios.

### Principios clave
- Minimizar la l√≥gica imperativa en el pipeline.
- Usar archivos declarativos: YAML, Terraform, Helm, Kustomize.
- Evitar pipelines monol√≠ticos ‚Üí fomentar pipelines por servicio/m√≥dulo.
- Mantener tiempos de ejecuci√≥n predecibles y razonables.
- Todo cambio debe ser auditable y reproducible.

---

## Fase de Build
### Recomendaciones
- Builds determin√≠sticas (reproducible builds).
- Cacheo agresivo: dependencias, compilaci√≥n, capas Docker.
- Versionado sem√°ntico automatizado o convencional (SemVer).
- Generaci√≥n de **SBOM** con Syft/Trivy.
- Firmas de artefactos (cosign, sterna).

### Artefactos generados
- Im√°genes Docker inmutables.
- Binarios, librer√≠as, charts o manifests empaquetados.

---

## Fase de Testing
### Tipos de pruebas a incluir
- Unitarias: r√°pidas y completas.
- Integraci√≥n: red, I/O, bases de datos.
- Contratos: validaci√≥n entre microservicios.
- E2E: simulaci√≥n de usuario real.
- Mutaci√≥n: resistencia de las pruebas.
- Regresi√≥n: escenarios cr√≠ticos.
- Performance: latencias, cargas sostenidas.
- Seguridad: SAST, DAST, secret scanning.

### Buenas pr√°cticas
- Fallar r√°pido (fail-fast).
- Paralelizar tests.
- Generar reportes: cobertura, resultados y m√©tricas.

---

## Fase de Seguridad (DevSecOps)
### Checks recomendados
- An√°lisis est√°tico de c√≥digo (CodeQL, Sonar).
- An√°lisis din√°mico (DAST).
- Escaneo de dependencias.
- Validaci√≥n de IaC con OPA/Conftest/Sentinel.
- Comprobaci√≥n de pol√≠ticas de seguridad obligatorias.
- Escaneo de contenedores antes de publicar.

### Reglas clave
- No despliegue sin firmar im√°genes.
- Eliminaci√≥n autom√°tica de secretos incrustados.
- Zero-trust en todos los entornos.

---

## Fase de Infraestructura como C√≥digo (IaC)
### Pr√°cticas
- Modo ‚Äúplan ‚Üí review ‚Üí apply‚Äù siempre.
- Revisar y versionar todos los cambios.
- Validar pol√≠ticas y configuraci√≥n antes del apply.
- Aplicar en entornos siempre iguales (ephemeral environments).

### Recomendaciones
- Estandarizar m√≥dulos/proveedores Terraform.
- Integrar Helm, Kustomize o ArgoCD para Kubernetes.

---

## Despliegues Progresivos
### Estrategias recomendadas
- **Blue/Green**: alta seguridad.
- **Canary**: despliegue gradual basado en porcentajes.
- **Shadow**: replicaci√≥n de tr√°fico real sin impacto.
- **Feature flags**: desacoplar deploy de release.

### Reglas de oro
- Los despliegues deben ser reversibles autom√°ticamente.
- Guardar siempre m√©tricas pre y post-release.
- Reducir riesgos bas√°ndose en observabilidad, no en tiempos.

---

## Multi-Regi√≥n y Multi-Cloud
### Buenas pr√°cticas
- Despliegues regionales escalonados.
- Sincronizaci√≥n de estados y metadatos.
- Control de versi√≥n homog√©neo entre regiones.
- Replicaci√≥n/CDC para bases de datos.
- Failover autom√°tico con health checks globales.

### Consideraciones
- La regi√≥n secundaria debe probarse primero.
- Evitar drift entre configuraciones multi-nube.

---

## Service Mesh en Pipeline
### Validaciones obligatorias
- Inyecci√≥n de sidecars correcta.
- mTLS forzado.
- VirtualServices y DestinationRules validados.
- Retries, timeouts, circuit breaking testeados.
- Observabilidad: m√©tricas y trazas de sidecar.

### Pr√°cticas avanzadas
- Validar pol√≠ticas de tr√°fico antes del rollout.
- Ensayos de resiliencia dentro del pipeline (latency injection).

---

## Observabilidad Integrada
### M√©tricas recomendadas
- P95/P99 latency.
- Error rate.
- Throughput.
- Saturaci√≥n.
- Health de endpoints cr√≠ticos.
- Logs clave y trazas distribuidas.

### Reglas
- No promover una versi√≥n si hay degradaci√≥n.
- Integrar Prometheus, Grafana, Loki, OpenTelemetry.

---

## Automatizaci√≥n de Rollbacks
### Criterios t√≠picos
- Spike de errores 5xx.
- Aumento en latencia p95/p99.
- Downtime detectado por health checks.
- Anomal√≠as en logs detectadas por ML simple.

### Pr√°cticas
- Rollback autom√°tico debe ser inmediato.
- Registrar siempre raz√≥n del rollback.
- Mantener pol√≠tica de retenci√≥n para im√°genes previas.

---

## Gobernanza, Auditor√≠a y Cumplimiento
### Reglas de compliance
- Aprobaciones dobles en entornos regulados.
- Trazabilidad completa del pipeline.
- Logs inmutables de auditor√≠a.
- Controles de acceso RBAC/ABAC en CI/CD.
- Escaneo autom√°tico de permisos excesivos.

### Integraci√≥n
- CMDB, sistemas ITSM, plataformas de auditor√≠a.

---

## Eficiencia y Confiabilidad del Pipeline
### Recomendaciones
- Niveles de cach√© bien dise√±ados.
- Ejecuci√≥n de jobs en paralelo.
- Workers escalables y autoservicio.
- Uso de pipelines ef√≠meros por PR.
- Reutilizaci√≥n de m√≥dulos, plantillas y jobs est√°ndar.

---

## Gesti√≥n de Secretos
### Pr√°cticas
- Nada de secretos en repositorios.
- Rotaci√≥n obligatoria.
- Uso de Vault, KMS, SOPS o Sealed Secrets.
- Acceso basado en identidad, no en archivos.

---

## Buenas Pr√°cticas para Monorepos y Multi-Repo
### Monorepo
- Determinar cambios para ejecutar s√≥lo pipelines necesarios.
- Caching optimizado.
- Dependencias aisladas por servicio.

### Multi-Repo
- Pipelines independientes y reproducibles.
- Versionado estricto entre servicios.

---

## Entornos ef√≠meros (Preview Environments)
### Beneficios
- Cada PR se prueba en un entorno real.
- Pruebas E2E reales sin afectar otros equipos.
- Acelera el merge y reduce bugs.

---

## Documentaci√≥n y Conocimiento
- Documentar pipelines con diagrams-as-code (Mermaid).
- Mantener un cat√°logo de procesos CI/CD.
- Registrar flujos de despliegue y est√°ndares.

---

## Lista Resumida de Pr√°cticas Recomendadas
1. Pipelines declarativos y modulares.  
2. Build reproducible + firma de artefactos.  
3. Pruebas completas (unit, integration, contract, e2e).  
4. Validaciones de seguridad en cada paso.  
5. IaC revisado y auditado antes de aplicar.  
6. Despliegues progresivos (canary/blue-green).  
7. Observabilidad integrada y accionable.  
8. Rollbacks autom√°ticos basados en m√©tricas.  
9. Multi-regi√≥n escalonado.  
10. Service mesh validado en pipeline.  
11. Gesti√≥n estricta de secretos.  
12. Entornos ef√≠meros para pruebas realistas.  
13. Auditor√≠a y cumplimiento obligatorios.  
14. Documentaci√≥n actualizada y accesible.  

---

