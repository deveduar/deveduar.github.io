---
date: 2026-01-10 22:52
title: logstash
keywords:
source:
status: 
Parent: "[[Area-Sistemas]]"
public_note: "true"
category: monitoreo
tags:
  - elasticsearh
  - ELK
  - logstash
---
# Logstash

- [Elasticsearch](/monitoreo/elasticsearch/)
- [kibana](/monitoreo/kibana/)

## Definici贸n y prop贸sito
Logstash es una herramienta de ingesta y procesamiento de datos del stack Elastic. Su funci贸n principal es recolectar datos desde m煤ltiples fuentes, transformarlos mediante filtros y enviarlos a destinos como [Elasticsearch](/monitoreo/elasticsearch/). Act煤a como un pipeline flexible de [ETL ](/backend/etl/) orientado a datos en tiempo real.

## Arquitectura basada en pipelines
- **Input**
	- Define las fuentes de datos
	- Soporta archivos, TCP/UDP, HTTP, bases de datos, colas y brokers
	- Permite ingesti贸n continua o por lotes
- **Filter**
	- Etapa de transformaci贸n y enriquecimiento
	- Procesamiento estructurado y no estructurado
	- Normalizaci贸n de campos y formatos
- **Output**
	- Define los destinos finales
	- Uso m谩s com煤n: env铆o a [Elasticsearch](/monitoreo/elasticsearch/)
	- Soporte para m煤ltiples salidas simult谩neas

## Inputs m谩s utilizados
- **File**
	- Lectura de logs desde archivos locales
	- Seguimiento del offset para evitar reprocesos
- **Beats**
	- Recepci贸n de datos desde Filebeat, Metricbeat y otros
	- Uso com煤n en arquitecturas distribuidas
- **HTTP**
	- Recepci贸n de eventos v铆a API REST
	- Integraci贸n con aplicaciones externas
- **Kafka**
	- Consumo de streams de eventos
	- Alta escalabilidad y tolerancia a fallos

## Filtros principales
- **grok**
	- Parseo de texto no estructurado mediante patrones
	- Muy usado para logs de aplicaciones y servidores
- **mutate**
	- Renombrar, eliminar o convertir campos
	- Limpieza y normalizaci贸n de datos
- **date**
	- Conversi贸n de timestamps a formato est谩ndar
	- Clave para an谩lisis temporal en [kibana](/monitoreo/kibana/)
- **geoip**
	- Enriquecimiento con informaci贸n geogr谩fica
	- Uso com煤n en an谩lisis de tr谩fico y seguridad
- **json**
	- Parseo de payloads JSON
	- Conversi贸n autom谩tica a campos estructurados

## Outputs comunes
- **Elasticsearch**
	- Indexaci贸n directa de eventos procesados
	- Configuraci贸n de 铆ndices, pipelines y autenticaci贸n
- **File**
	- Escritura de eventos procesados a disco
	- Uso frecuente para depuraci贸n
- **Stdout**
	- Visualizaci贸n en consola
	- til en desarrollo y testing

## Configuraci贸n
- Basada en archivos `.conf`
- Sintaxis declarativa por secciones
- Permite m煤ltiples pipelines simult谩neos
- Soporte para variables de entorno

## Escalabilidad y rendimiento
- Procesamiento en paralelo mediante workers
- Ajuste de batch size y batch delay
- Posibilidad de escalar horizontalmente
- Integraci贸n con colas para desacoplar productores y consumidores

## Gesti贸n de errores y resiliencia
- Manejo de eventos fallidos
- Dead Letter Queue para datos no procesables
- Reintentos configurables
- Logs detallados para diagn贸stico

## Casos de uso comunes
- Centralizaci贸n de logs
- Normalizaci贸n de datos heterog茅neos
- Enriquecimiento de eventos antes de indexar
- Integraci贸n de sistemas legacy
- Procesamiento previo a anal铆tica y observabilidad

## Relaci贸n con Kibana y Elasticsearch
- Logstash prepara y estructura los datos
- [Elasticsearch](/monitoreo/elasticsearch/) los indexa y almacena
- [kibana](/monitoreo/kibana/) los visualiza y analiza
- Juntos forman un flujo completo de observabilidad y an谩lisis

## Buenas pr谩cticas
- Mantener pipelines simples y modulares
- Usar grok de forma eficiente para evitar impacto en rendimiento
- Validar datos antes de indexar
- Separar pipelines por dominio o fuente
- Monitorizar el uso de memoria y CPU
