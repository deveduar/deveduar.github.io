---
date: 2024-11-18 19:35
title: TensorFlow
tags:
  - datascience
  - data-science
  - IA
  - tensorflow
keywords:
source:
status: üåü
Parent: "[[Area-Prog]]"
cssclasses:
  - hide-embedded-header1
  - wide
categories:
  - Data Science
public_note: "true"
category: Data Science
---
# TensorFlow
`$= dv.current().file.tags.join(" ")`

- [Data Science](/uncategorized/data-science/)
- [Deep Learning](/data%20science/deep-learning/)
- [Machine Learning](/data%20science/machine-learning/)
- keras

# Python: Red Neuronal con TensorFlow
- [python](/software%20engineering/python/)
- Snippet en **MassCode**
- [Tu primera red neuronal en Python y TensorFlow](https://www.youtube.com/watch?v=iX_on3VxZzk)
- [Google Colab](https://colab.research.google.com/notebooks/intro.ipynb?utm_source=scs-index)  
- [Keras Framework](https://keras.io/)
- [Tu primera red neuronal en Python y TensorFlow c√≥digo Google Colab](https://colab.research.google.com/drive/1ehETBOVtCqe7G6HOvm84hfXba8Gd9ILW?usp=sharing#scrollTo=FVDejrBgcokc)

### Conceptos Clave
- Capas de tipo densa: neuronas de entrada, ocultas y de salida.
- Modelo secuencial: estructura de capas apiladas.
- Pesos y sesgos: par√°metros internos de la red.
- Optimizador Adam: ajusta pesos y sesgos durante el entrenamiento.
- Tasa de aprendizaje: controla la magnitud de los ajustes en pesos y sesgos.
- Funci√≥n de p√©rdida: mide el error entre predicciones y valores reales; penaliza errores grandes y peque√±os.
- Compilar modelo: define optimizador, funci√≥n de p√©rdida y m√©tricas.
- Entrenamiento del modelo:
	- Funci√≥n `fit()`: recibe datos de entrada y resultados esperados.
	- Epochs: n√∫mero de iteraciones sobre los datos.
	- Verbose: controla la visualizaci√≥n de progreso.
- Conversi√≥n de unidades: por ejemplo, Celsius a Fahrenheit.
- Visualizaci√≥n de resultados: gr√°ficas de entrenamiento y validaci√≥n.
- Estructura interna de la red: variables internas, pesos, activaciones.
- Flujo de la red: c√≥mo los datos atraviesan las capas y se procesan.

### Ejemplo de C√≥digo: Red Neuronal Simple

{% raw %}
```python
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
import numpy as np

# Datos de ejemplo: Celsius a Fahrenheit
celsius = np.array([-40, -10, 0, 8, 15, 22, 38], dtype=float)
fahrenheit = np.array([-40, 14, 32, 46, 59, 72, 100], dtype=float)

# Crear modelo secuencial
model = keras.Sequential([
	layers.Dense(units=1, input_shape=[1])
])

# Compilar modelo
model.compile(optimizer='adam', loss='mean_squared_error')

# Entrenar modelo
history = model.fit(celsius, fahrenheit, epochs=500, verbose=0)

# Predicciones
print(model.predict([100.0]))
```
{% endraw %}`

### Visualizaci√≥n del Entrenamiento

{% raw %}
```python
import matplotlib.pyplot as plt

plt.plot(history.history['loss'])
plt.title('P√©rdida durante el entrenamiento')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.show()
```
{% endraw %}

### Expansi√≥n de Conceptos

- **Activaciones:** funciones que determinan la salida de cada neurona.
- **Overfitting y underfitting:** ajustar modelo para que generalice sin memorizar datos.
- **Regularizaci√≥n:** t√©cnicas como `Dropout` para evitar overfitting.
- **Batch size:** n√∫mero de muestras procesadas antes de actualizar pesos.
- **Callback:** funciones que permiten monitorizar o modificar el entrenamiento en tiempo real.
- **Pipeline de datos:** normalizaci√≥n, escalado y preprocesamiento de los datos antes de entrar a la red.
- **Visualizaci√≥n de la arquitectura:** herramientas como `plot_model()` para inspeccionar la estructura de la red.

# TensorFlow Avanzado

## Tipos de Capas Avanzadas
- **Convolucionales (Conv2D, Conv1D):**  
	- Ideales para procesamiento de im√°genes o secuencias con patrones espaciales.  
	- Extraen caracter√≠sticas locales mediante filtros (kernels).  
	- Combinadas con capas de pooling para reducci√≥n de dimensionalidad.
- **Recurrentes (LSTM, GRU):**  
	- Dise√±adas para secuencias temporales o datos dependientes del orden.  
	- Mantienen un "estado" interno que permite recordar informaci√≥n pasada.  
	- GRU (Gated Recurrent Unit) es m√°s ligera que LSTM pero con comportamiento similar.
- **Embeddings:**  
	- Transforman datos categ√≥ricos o palabras en vectores densos de dimensi√≥n fija.  
	- Usadas principalmente en NLP y recomendaciones.  
	- Permiten capturar relaciones sem√°nticas entre elementos.

## Funciones de Activaci√≥n y su Impacto
- **ReLU (Rectified Linear Unit):** activa la neurona solo si la entrada > 0, evita saturaci√≥n y acelera el entrenamiento.  
- **Sigmoid:** convierte valores a rango [0,1], √∫til en salidas binarias, pero propenso a gradientes peque√±os.  
- **Tanh:** rango [-1,1], centrado en cero, √∫til para normalizaci√≥n de activaciones internas.  
- **Softmax:** convierte un vector en probabilidades que suman 1, usado en clasificaci√≥n multiclase.

## M√©tricas de Evaluaci√≥n
- **MAE (Mean Absolute Error):** error promedio absoluto, menos sensible a outliers.  
- **MSE (Mean Squared Error):** penaliza m√°s errores grandes, √∫til para regresi√≥n.  
- **Accuracy:** porcentaje de predicciones correctas, ideal para clasificaci√≥n balanceada.  
- **Precision:** proporci√≥n de predicciones positivas correctas, importante en clasificaci√≥n desequilibrada.  
- **Recall:** proporci√≥n de positivos reales detectados, mide sensibilidad del modelo.

## T√©cnicas de Optimizaci√≥n Avanzadas
- **Learning Rate Scheduling:** ajuste din√°mico de la tasa de aprendizaje seg√∫n epochs o performance.  
- **Gradient Clipping:** limita el tama√±o m√°ximo del gradiente para evitar explosi√≥n de gradientes en redes profundas o recurrentes.

## Guardado y Carga de Modelos
- **model.save('ruta_modelo.h5')**: guarda arquitectura, pesos y optimizador en un archivo.  
- **keras.models.load_model('ruta_modelo.h5')**: carga un modelo completo listo para inferencia o reentrenamiento.

## Transfer Learning
- Uso de modelos preentrenados en tareas similares.  
- Permite ahorrar tiempo y mejorar precisi√≥n con menos datos.  
- Ejemplo: usar `ResNet50` para clasificaci√≥n de im√°genes y ajustar solo las capas finales.

## Deploy de Modelos
- Exportaci√≥n a producci√≥n:
	- **Web:** TensorFlow.js.  
	- **M√≥vil:** TensorFlow Lite (Android/iOS).  
	- **Servidor:** APIs REST usando Flask, FastAPI o TensorFlow Serving.  
- Consideraciones: tama√±o del modelo, latencia y compatibilidad de hardware.

## Visualizaci√≥n Avanzada
- **TensorBoard:** monitorizaci√≥n de m√©tricas, p√©rdidas, histogramas de pesos y activaciones.  
- Gr√°ficas en tiempo real durante entrenamiento, √∫til para detectar overfitting o underfitting.  
- Permite comparar m√∫ltiples entrenamientos y ajustar hiperpar√°metros.

## Conceptos de Arquitectura
- N√∫mero de capas ocultas: m√°s capas permiten aprender representaciones complejas, pero aumentan riesgo de overfitting.  
- Neuronas por capa: m√°s neuronas capturan m√°s informaci√≥n, pero incrementan costo computacional.  
- Conexiones: densas, convolucionales o recurrentes seg√∫n la tarea.  
- Pesos iniciales: inicializaci√≥n correcta (He, Glorot) mejora la convergencia del entrenamiento.

## Tipos de Problemas
- **Regresi√≥n:** predicci√≥n de valores continuos (ej. temperatura, precios).  
- **Clasificaci√≥n:** asignaci√≥n de categor√≠as discretas (binaria o multiclase).  
- **Series temporales:** predicci√≥n de secuencias en el tiempo (ej. stock, demanda).  
- **NLP (Natural Language Processing):** an√°lisis de texto, traducci√≥n, clasificaci√≥n de sentimientos, generaci√≥n de texto.

# Fundamentos de TensorFlow

## Qu√© es TensorFlow
- Framework de c√≥digo abierto desarrollado por Google para computaci√≥n num√©rica y machine learning.  
- Permite construir, entrenar y desplegar modelos de aprendizaje autom√°tico y deep learning.  
- Basado en grafos de flujo de datos donde los nodos representan operaciones y los bordes representan tensores.

## Tensores
- Estructuras de datos multidimensionales (arrays) que transportan informaci√≥n en TensorFlow.  
- Tipos: `tf.constant`, `tf.Variable`, `tf.Tensor`.  
- Operaciones b√°sicas: suma, multiplicaci√≥n, reshape, slicing, concatenaci√≥n.  
- Ejemplo:

{% raw %}
```python
import tensorflow as tf

a = tf.constant([[1, 2], [3, 4]])
b = tf.Variable([[5, 6], [7, 8]])
c = tf.add(a, b)
print(c)
```
{% endraw %}`

## Computaci√≥n con Grafos

- **Grafos est√°ticos:** definici√≥n de operaciones antes de la ejecuci√≥n (TensorFlow 1.x).
- **Eager Execution:** evaluaci√≥n inmediata de operaciones (TensorFlow 2.x, modo por defecto).
- Ventajas: optimizaci√≥n de operaciones, paralelizaci√≥n, compatibilidad con GPU/TPU.

## Variables y Constantes

- **Constantes:** valores fijos que no cambian durante el entrenamiento (`tf.constant`).
- **Variables:** par√°metros que se actualizan durante el entrenamiento (`tf.Variable`).
- Importancia: pesos, sesgos y par√°metros ajustables.

## Operaciones Matem√°ticas

- Aritm√©tica: suma, resta, multiplicaci√≥n, divisi√≥n.
- Funciones lineales y no lineales: `tf.matmul`, `tf.reduce_sum`, `tf.square`.
- Funciones de activaci√≥n: `tf.nn.relu`, `tf.nn.sigmoid`, `tf.nn.tanh`.

## TensorFlow y Keras

- **Keras:** API de alto nivel integrada en TensorFlow para construir modelos de manera sencilla.
- Permite crear modelos secuenciales y funcionales.
- Simplifica compilaci√≥n, entrenamiento y evaluaci√≥n de modelos.

{% raw %}
```python
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense

model = Sequential([
	Dense(10, activation='relu', input_shape=(5,)),
	Dense(1)
])
model.compile(optimizer='adam', loss='mse')
```
{% endraw %}

## Entrenamiento de Modelos

- Funci√≥n `fit()`: realiza forward pass, calcula p√©rdida y backpropagation para actualizar pesos.
- Par√°metros clave: `epochs`, `batch_size`, `verbose`.
- Funci√≥n de p√©rdida: mide qu√© tan lejos est√°n las predicciones de los valores reales.
- Optimizadores: ajustan pesos y sesgos (ej. Adam, SGD, RMSProp).

## Evaluaci√≥n y Predicci√≥n

- Funci√≥n `evaluate()`: calcula la p√©rdida y m√©tricas en datos de validaci√≥n o prueba.
- Funci√≥n `predict()`: genera predicciones sobre nuevos datos.

## GPU y TPU

- TensorFlow detecta autom√°ticamente GPUs disponibles para acelerar c√°lculos.
- TPU (Tensor Processing Unit) optimizado para operaciones de deep learning a gran escala.

## Flujo de Trabajo B√°sico

1. Preparar datos: normalizaci√≥n, escalado, batch.
2. Definir modelo: capas, activaciones, arquitectura.
3. Compilar modelo: elegir optimizador, funci√≥n de p√©rdida y m√©tricas.
4. Entrenar modelo: `fit()`.
5. Evaluar modelo: `evaluate()`.
6. Guardar y desplegar: `model.save()`, exportaci√≥n a producci√≥n o dispositivos m√≥viles.

# Laboratorios y Casos de Uso con TensorFlow

## Laboratorios Sugeridos

- **Lab 1: Red Neuronal Simple**
	- Crear un modelo secuencial con capas densas.
	- Problema: predicci√≥n de temperatura Celsius a Fahrenheit.
	- Objetivos: entender tensores, capas densas, funci√≥n de p√©rdida, optimizador y entrenamiento b√°sico.

- **Lab 2: Clasificaci√≥n de Im√°genes con CNN**
	- Usar capas convolucionales, pooling y fully connected.
	- Dataset: MNIST o CIFAR-10.
	- Objetivos: extracci√≥n de caracter√≠sticas, overfitting/underfitting, visualizaci√≥n de filtros.

- **Lab 3: Predicci√≥n de Series Temporales**
	- Modelo LSTM o GRU.
	- Dataset: precios de acciones o demanda energ√©tica.
	- Objetivos: secuencias temporales, estado interno, backpropagation a trav√©s del tiempo.

- **Lab 4: NLP B√°sico con Embeddings**
	- Clasificaci√≥n de sentimientos o an√°lisis de texto.
	- Usar embeddings preentrenados o propios.
	- Objetivos: vectorizaci√≥n de palabras, capas recurrentes, tokenizaci√≥n.

- **Lab 5: Transfer Learning**
	- Usar un modelo preentrenado como ResNet50 o MobileNet.
	- Problema: clasificaci√≥n de im√°genes espec√≠fica (ej. frutas, animales).
	- Objetivos: congelar capas, reentrenar solo las capas finales.

- **Lab 6: Regularizaci√≥n y Optimizaci√≥n Avanzada**
	- Implementar Dropout, batch normalization y learning rate scheduling.
	- Dataset: cualquier problema de clasificaci√≥n o regresi√≥n.
	- Objetivos: mejorar generalizaci√≥n y estabilidad del entrenamiento.

- **Lab 7: Deploy de Modelos**
	- Convertir un modelo entrenado a TensorFlow Lite o TensorFlow.js.
	- Objetivos: probar inferencia en m√≥viles, web o API REST.

- **Lab 8: Visualizaci√≥n con TensorBoard**
	- Monitorizar m√©tricas, p√©rdidas, histogramas de pesos.
	- Objetivos: entender comportamiento del entrenamiento y detectar problemas de convergencia.

## Casos de Uso Reales

- **Visi√≥n por Computadora**
	- Detecci√≥n de objetos en im√°genes y video.
	- Clasificaci√≥n m√©dica (radiograf√≠as, resonancias).
	- Reconocimiento facial o gestos.

- **Procesamiento de Lenguaje Natural (NLP)**
	- Chatbots, asistentes virtuales.
	- Traducci√≥n autom√°tica.
	- Clasificaci√≥n de sentimientos o an√°lisis de opiniones.

- **Series Temporales y Predicci√≥n**
	- Pron√≥stico de ventas, demanda energ√©tica o precios de acciones.
	- Detecci√≥n de anomal√≠as en sensores industriales.
	- Predicci√≥n del clima y patrones meteorol√≥gicos.

- **Sistemas de Recomendaci√≥n**
	- Recomendaci√≥n de productos, pel√≠culas o m√∫sica.
	- Uso de embeddings para representar usuarios y items.

- **Automatizaci√≥n y Rob√≥tica**
	- Control de robots con aprendizaje reforzado.
	- Veh√≠culos aut√≥nomos: percepci√≥n y planificaci√≥n de rutas.

- **Optimizaci√≥n de Procesos**
	- Modelos de predicci√≥n para log√≠stica y supply chain.
	- Mantenimiento predictivo de maquinaria industrial.
# Recursos TensorFlow (Estado a 2025‚Äë2026)

## Cursos y Formaci√≥n Actualizada
- **[Tensorflow 2: Deep Learning & Artificial Intelligence (2026)](https://www.udemy.com/course/deep-learning-tensorflow-2/)** ‚Äì Curso completo con visi√≥n, series temporales, NLP, GANs, Reinforcement Learning, transfer learning, despliegue con TensorFlow Serving y TensorFlow Lite. √öltima actualizaci√≥n en 1/2026.
- **[TensorFlow - Hands‚Äëon Machine Learning with TensorFlow 2026](https://www.udemy.com/course/tensorflow-hands-on-machine-learning-with-tensorflow/)** ‚Äì Enfoque pr√°ctico con regresi√≥n lineal y log√≠stica usando TensorFlow.
- **[Curso de Deep Learning con TensorFlow y Keras (OpenWebinars)](https://openwebinars.net/cursos/deep-learning-tensorflow-keras/)** ‚Äì Formaci√≥n pr√°ctica y ejemplos para redes neuronales con TensorFlow y Keras en espa√±ol.
- **[DEEP LEARNING: DOMINA LAS REDES NEURONALES CON TENSORFLOW Y PYTHON (AIN)](https://www.ain.es/formacion/curso/deep-learning-rede-neuronales-tensorflow-python/)** ‚Äì Curso online con redes convolucionales, recurrentes y no supervisado.

## Documentaci√≥n Oficial y Tutoriales
- **[Tutorials | TensorFlow Core](https://www.tensorflow.org/tutorials)** ‚Äì Repositorio oficial de tutoriales de TensorFlow con ejemplos y gu√≠as para diversos casos de uso (visi√≥n, texto, etc.).
- **[Machine learning education | TensorFlow](https://www.tensorflow.org/resources/learn-ml)** ‚Äì Recursos agrupados por la propia comunidad oficial, con cursos, libros y gu√≠as para producci√≥n, m√≥vil y web.

## Rutas de Aprendizaje y Gu√≠as Recomendadas
- **[TensorFlow Resources Roadmap](https://tensorflow-world-resources.readthedocs.io/en/latest/content/books.html)** ‚Äì Compilaci√≥n de libros, cursos, tutoriales y proyectos para estructurar tu aprendizaje completo de TensorFlow.
- **[Ruta de aprendizaje en Hackr.io (2025)](https://hackr.io/tutorials/learn-tensorflow)** ‚Äì Listado curado de cursos y tutoriales sugeridos por la comunidad con opciones gratuitas y de pago.

## Libros y Referencias Destacadas
- **[Hands‚ÄëOn Machine Learning with TensorFlow 2.0 (G√©ron)](https://umatechnology.org/11-best-tensorflow-books-2025-update/)** ‚Äì Gu√≠a pr√°ctica actualizada para implementar proyectos reales con TensorFlow.
- **[Deep Learning with TensorFlow 2 and Keras](https://umatechnology.org/11-best-tensorflow-books-2025-update/)** ‚Äì Recurso intermedio/avanzado para construir y comprender redes profundas.
- **[Introduction to Computer Vision with TensorFlow (Thompson Carter)](https://bookauthority.org/books/new-tensorflow-books)** ‚Äì Libro enfocado en visi√≥n artificial con casos pr√°cticos de CNNs y GANs.
- Libros recomendados por TensorFlow.org como *AI and Machine Learning for Coders*, *Deep Learning with Python*, y otros t√≠tulos cl√°sicos de fundamentos ML y DL. ([TensorFlow Resources](https://www.tensorflow.org/resources/learn-ml))

## Recursos Complementarios
- **[Recursos t√©cnicos de Deep Learning (NVIDIA)](https://www.nvidia.com/es-es/training/resources/)** ‚Äì Web con materiales para ampliar habilidades en Deep Learning con TensorFlow y otros frameworks.
- **[Materiales de cursos acad√©micos y gu√≠as docentes 2025‚Äë26](https://apps.stic.uva.es/guias_docentes/uploads/2025/512/46633/1/Documento.pdf)** ‚Äì Bibliograf√≠as universitarias que incluyen textos cl√°sicos y modernos sobre redes neuronales y TensorFlow.

## Recursos para Especializaci√≥n y Producci√≥n
- **[TensorFlow Learning Paths (oficial)](https://www.tensorflow.org/resources/learn-ml)** ‚Äì Rutas espec√≠ficas para despliegue m√≥vil (TensorFlow Lite / LiteRT), web (TensorFlow.js), y producci√≥n usando TFX.
- **[TensorBoard y producci√≥n ML](https://www.tensorflow.org/resources/learn-ml)** ‚Äì Documentaci√≥n oficial incluye herramientas para monitorizaci√≥n y MLOps que facilitan llevar modelos de entrenamiento a producci√≥n.

## Consejos de la Comunidad (Opiniones y Tendencias)
- En 2025 la comunidad de desarrolladores ML discute sobre evoluci√≥n del ecosistema y comparaci√≥n de frameworks (ej. TensorFlow vs PyTorch), lo cual puede ser √∫til para posicionar tus habilidades seg√∫n la demanda actual. ([Reddit r/MachineLearning](https://www.reddit.com/r/MachineLearningJobs/comments/1nssvef))
