---
date: 2025-08-09 13:48
title: LLM
keywords:
source:
status: üìå
Parent: "[[Area-IA]]"
public_note: "true"
category: Data Science
tags:
  - LLM
  - IA
---
# LLM

- [Data Science](/data%20science/data-science/)
- IA
- [AIOps](/gestion%20de%20negocio/aiops/)
- [cloud](/cloud/cloud/)
- [Prompt Engineering](/data%20science/prompt-engineering/)
- [TensorFlow](/data%20science/tensorflow/)

## Definici√≥n
Los **Large Language Models (LLM)** son modelos de aprendizaje autom√°tico entrenados sobre grandes vol√∫menes de texto para comprender, generar y transformar lenguaje natural. Se basan principalmente en arquitecturas de tipo *transformer* y aprenden patrones estad√≠sticos del lenguaje para producir respuestas coherentes y contextuales.

## Componentes clave
-	**Datos de entrenamiento**: grandes corpus de texto (documentaci√≥n, libros, c√≥digo, conversaciones).
-	**Arquitectura transformer**: atenci√≥n autom√°tica (*self-attention*) para capturar relaciones entre tokens.
-	**Tokens y embeddings**: representaci√≥n num√©rica del lenguaje.
-	**Preentrenamiento y ajuste fino**: aprendizaje general seguido de especializaci√≥n por tareas o dominios.
-	**Inferencia**: generaci√≥n de texto a partir de *prompts*.

## Casos de uso
-	Asistentes conversacionales y chatbots.
-	Generaci√≥n y resumen de textos.
-	Traducci√≥n autom√°tica.
-	An√°lisis y generaci√≥n de c√≥digo.
-	Extracci√≥n de informaci√≥n y clasificaci√≥n de documentos.
-	Soporte a la toma de decisiones basada en texto.

## Relaci√≥n con √°reas
-	IA: los LLM son un subcampo de la inteligencia artificial centrado en el lenguaje.
-	[Data Science](/data%20science/data-science/): se usan para exploraci√≥n de datos textuales, NLP y automatizaci√≥n de an√°lisis.
-	[cloud](/cloud/cloud/): suelen desplegarse y escalarse en infraestructuras cloud para entrenamiento e inferencia.

## Arquitectura y entrenamiento
-	Entrenamiento supervisado y no supervisado.
-	Aprendizaje por refuerzo con retroalimentaci√≥n humana (RLHF).
-	Uso intensivo de GPU/TPU.
-	Escalado del modelo (par√°metros, datos y c√≥mputo).

## Limitaciones y riesgos
-	Alucinaciones (respuestas incorrectas pero plausibles).
-	Sesgos heredados de los datos.
-	Alto costo computacional.
-	Dependencia del *prompting*.
-	Consideraciones √©ticas y de privacidad.

## Herramientas y ecosistema
-	Frameworks de ML (PyTorch, [TensorFlow](/data%20science/tensorflow/)).
-	Bibliotecas NLP (Hugging Face).
-	APIs de modelos comerciales y open-source.
-	Integraci√≥n con pipelines de datos y sistemas productivos.

# LLM

## Prompting y control de comportamiento
-	Prompt engineering: dise√±o estructurado de instrucciones para guiar el razonamiento y la salida del modelo.
-	**System / user / assistant prompts**: separaci√≥n de roles para mayor control contextual.
-	**Chain-of-thought y reasoning**: t√©cnicas para mejorar la coherencia en tareas complejas.
-	**Few-shot / zero-shot learning**: adaptaci√≥n sin reentrenamiento.
-	**Prompt templates**: estandarizaci√≥n para sistemas productivos.

## Evaluaci√≥n y m√©tricas
-	**M√©tricas autom√°ticas**: perplexity, BLEU, ROUGE, accuracy por tarea.
-	**Evaluaci√≥n humana**: calidad, utilidad, alineaci√≥n y seguridad.
-	**Benchmarks**: conjuntos de pruebas estandarizados por dominio.
-	**Evaluaci√≥n continua**: monitoreo en producci√≥n para detectar degradaci√≥n.

## Memoria y contexto
-	**Context window**: l√≠mite de tokens que el modelo puede considerar.
-	**Memoria externa**: uso de bases de datos o vectores para persistencia.
-	**Recuperaci√≥n de contexto**: selecci√≥n din√°mica de informaci√≥n relevante.
-	**Estado conversacional**: manejo de historial y continuidad.

## Retrieval-Augmented Generation (RAG)
-	**B√∫squeda sem√°ntica**: embeddings y similitud vectorial.
-	**Fuentes externas**: documentos, bases de datos, APIs.
-	**Grounding**: reducci√≥n de alucinaciones mediante evidencia expl√≠cita.
-	**Pipelines RAG**: ingesti√≥n, indexaci√≥n, recuperaci√≥n y generaci√≥n.

## Agentes y orquestaci√≥n
-	**LLM como agente**: capacidad de planificar y ejecutar pasos.
-	**Herramientas (tools)**: llamadas a funciones, c√≥digo o servicios externos.
-	**Multi-agent systems**: colaboraci√≥n entre modelos especializados.
-	**Orquestadores**: control de flujos, estados y decisiones.

## Despliegue y operaci√≥n
-	**Model serving**: endpoints, latencia y throughput.
-	**Optimizaci√≥n**: cuantizaci√≥n, distilaci√≥n, batching.
-	**Escalabilidad**: balanceo de carga y autoscaling.
-	**Observabilidad**: logs, trazas y m√©tricas de uso.

## Gobernanza y cumplimiento
-	**Pol√≠ticas de uso**: l√≠mites funcionales y de seguridad.
-	**Auditor√≠a**: trazabilidad de prompts y respuestas.
-	**Privacidad**: manejo de datos sensibles y anonimizaci√≥n.
-	**Cumplimiento legal**: regulaciones locales e internacionales.

## Impacto organizacional
-	**Automatizaci√≥n cognitiva**: cambio en flujos de trabajo.
-	**Productividad**: aceleraci√≥n de tareas basadas en conocimiento.
-	**Nuevos roles**: prompt designers, AI engineers, AI ops.
-	**Adopci√≥n responsable**: capacitaci√≥n y gesti√≥n del cambio.

## Tendencias y evoluci√≥n
-	**Modelos multimodales**: texto, imagen, audio y video.
-	**Modelos m√°s peque√±os y eficientes**.
-	**Personalizaci√≥n por dominio**.
-	**Integraci√≥n profunda con sistemas empresariales**.

## Relaci√≥n ampliada con √°reas
-	IA: alineaci√≥n, agentes aut√≥nomos y sistemas h√≠bridos.
-	[Data Science](/data%20science/data-science/): feature extraction sem√°ntica y an√°lisis avanzado.
-	[cloud](/cloud/cloud/): infraestructura distribuida y MLOps para LLM.

# Recursos y herramientas LLM y Generative AI (2025‚Äì2026)

## Modelos de lenguaje (LLM) relevantes
-	**Llama 4** ‚Äì Nuevo modelo de Meta con variantes avanzadas y multimodales (Scout y Maverick) y enfoque en colaboraci√≥n creativa e integraci√≥n con herramientas. [Meta AI ‚Äì Llama](https://ai.meta.com/llama/)
-	**Gemini 2.5** ‚Äì Modelo de Google con capacidades multimodales (texto, imagen, audio, video) y gran ventana de contexto, disponible en Google AI Studio y Vertex AI. [Gemini](https://deepmind.google/technologies/gemini/)
-	**Gemma (serie)** ‚Äì Familia de modelos open-source de Google DeepMind en m√∫ltiples tama√±os, con variantes especializadas. [Gemma](https://ai.google.dev/gemma)
-	**Mistral AI (modelos)** ‚Äì Serie de modelos open-source y comerciales orientados a razonamiento, c√≥digo y eficiencia. [Mistral AI](https://mistral.ai/)
-	**Am√°lia (LLM portugu√©s)** ‚Äì Modelo en desarrollo enfocado en lengua portuguesa y administraci√≥n p√∫blica (estado 2026). [Am√°lia LLM](https://pt.wikipedia.org/wiki/Am%C3%A1lia_(modelo_de_linguagem))
-	**Manus (agente aut√≥nomo)** ‚Äì Agente de IA dise√±ado para ejecutar tareas complejas de forma aut√≥noma. [Manus](https://es.wikipedia.org/wiki/Manus_(agente_de_IA))
-	**GLM-4.5-Air** ‚Äì Modelo empresarial optimizado para agentes y flujos de trabajo corporativos. [Zhipu AI ‚Äì GLM](https://www.zhipu.ai/)
-	**Qwen2.5-VL-7B-Instruct** ‚Äì Modelo multimodal eficiente en coste, orientado a visi√≥n y lenguaje. [Qwen](https://qwenlm.github.io/)

## Frameworks y bibliotecas para desarrollo e ingenier√≠a
-	**Transformers (Hugging Face)** ‚Äì Ecosistema l√≠der para modelos, datasets y evaluaci√≥n. [Hugging Face Transformers](https://huggingface.co/docs/transformers)
-	**LangChain / LlamaIndex** ‚Äì Frameworks para RAG, memoria, agentes y orquestaci√≥n. [LangChain](https://www.langchain.com/) ¬∑ [LlamaIndex](https://www.llamaindex.ai/)
-	**DeepSpeed** ‚Äì Optimizaci√≥n de entrenamiento e inferencia a gran escala. [DeepSpeed](https://www.deepspeed.ai/)
-	**PyTorch 3.x** ‚Äì Framework principal con mejoras de rendimiento y compilaci√≥n. [PyTorch](https://pytorch.org/)
-	**TensorFlow 3.0 + TFX** ‚Äì Plataforma de ML con pipelines productivos. [TensorFlow](https://www.tensorflow.org/)
-	**JAX + Flax** ‚Äì Computaci√≥n num√©rica y modelos de alto rendimiento. [JAX](https://jax.readthedocs.io/) ¬∑ [Flax](https://flax.readthedocs.io/)
-	**Ray + Anyscale** ‚Äì Ejecuci√≥n distribuida y escalado de aplicaciones LLM. [Ray](https://www.ray.io/) ¬∑ [Anyscale](https://www.anyscale.com/)
-	**OpenVINO / ONNX Runtime** ‚Äì Optimizaci√≥n y despliegue en edge y producci√≥n. [OpenVINO](https://docs.openvino.ai/) ¬∑ [ONNX Runtime](https://onnxruntime.ai/)
-	**FastAPI + BentoML / MLflow** ‚Äì Stack MLOps para serving, versionado y observabilidad. [FastAPI](https://fastapi.tiangolo.com/) ¬∑ [BentoML](https://bentoml.com/) ¬∑ [MLflow](https://mlflow.org/)
-	**PyTorch Lightning** ‚Äì Abstracci√≥n para entrenamiento y experimentaci√≥n reproducible. [PyTorch Lightning](https://lightning.ai/)

## Protocolos y est√°ndares
-	**Model Context Protocol (MCP)** ‚Äì Est√°ndar para conectar LLMs con herramientas y aplicaciones externas. [MCP](https://modelcontextprotocol.io/)

## Bases de datos y sistemas de vectores
-	**FAISS** ‚Äì B√∫squeda vectorial eficiente. [FAISS](https://github.com/facebookresearch/faiss)
-	**Weaviate** ‚Äì Base de datos vectorial con capacidades sem√°nticas. [Weaviate](https://weaviate.io/)
-	**Qdrant** ‚Äì Vector database orientada a rendimiento y simplicidad. [Qdrant](https://qdrant.tech/)

## Herramientas LLMOps y DevTools
-	**Unsloth AI** ‚Äì Fine-tuning eficiente de LLMs con bajo consumo de recursos. [Unsloth](https://unsloth.ai/)
-	**DeepEval** ‚Äì Evaluaci√≥n autom√°tica de LLMs. [DeepEval](https://deepeval.com/)
-	**Deepchecks** ‚Äì Validaci√≥n y testing de modelos ML/LLM. [Deepchecks](https://deepchecks.com/)
-	**Opik** ‚Äì Observabilidad y evaluaci√≥n de sistemas LLM. [Opik](https://www.comet.com/site/products/opik/)
-	**RAGAs** ‚Äì Evaluaci√≥n espec√≠fica para pipelines RAG. [RAGAs](https://github.com/explodinggradients/ragas)
-	**Phoenix** ‚Äì Observabilidad y debugging de aplicaciones LLM. [Phoenix](https://arize.com/phoenix/)
-	**Evalverse** ‚Äì Benchmarks y evaluaci√≥n comparativa de modelos. [Evalverse](https://evalverse.ai/)

## Hardware y aceleradores
-	**Microsoft Maia 200** ‚Äì Chip de IA optimizado para entrenamiento e inferencia a gran escala. [Microsoft Maia](https://azure.microsoft.com/en-us/blog/)
-	**AI HAT+ 2 para Raspberry Pi 5** ‚Äì Aceleraci√≥n local para modelos peque√±os y edge AI. [Raspberry Pi AI HAT+](https://www.raspberrypi.com/)

## Recursos educativos y aprendizaje
-	Gu√≠as y hubs sobre **APIs, modelos, bases vectoriales y herramientas de IA generativa**. [Hugging Face Learn](https://huggingface.co/learn)
-	Repositorios y proyectos open-source como *Ollama Deep Researcher* para investigaci√≥n asistida por LLM. [Ollama](https://ollama.com/)

## Estrategias de uso y workflows
-	Arquitecturas **RAG + agentes IA** con LangChain y LlamaIndex. [RAG Overview](https://www.llamaindex.ai/learn)
-	Integraci√≥n de LLMs en pipelines de ML, aplicaciones web y sistemas productivos mediante APIs y MLOps. [BentoML Guides](https://docs.bentoml.com/)

# LLM ‚Äî Arquitectura, funcionamiento interno y desarrollo

## Arquitectura interna

### Transformer
-	Arquitectura base de los LLM modernos.
-	Elimina recurrencia y convoluciones, usando atenci√≥n como mecanismo central.
-	Permite paralelizaci√≥n masiva durante el entrenamiento.

### Self-Attention
-	Cada token atiende a todos los dem√°s dentro de la ventana de contexto.
-	Captura dependencias largas y relaciones sem√°nticas.
-	Escala cuadr√°ticamente con el n√∫mero de tokens (impacto en costo).

### Multi-Head Attention
-	M√∫ltiples espacios de atenci√≥n en paralelo.
-	Cada cabeza aprende patrones distintos (sintaxis, sem√°ntica, contexto).
-	Concatenaci√≥n y proyecci√≥n final.

### Embeddings
-	**Token embeddings**: representaci√≥n vectorial de palabras/subpalabras.
-	**Positional embeddings**: codifican el orden de los tokens.
-	Variantes modernas: rotary embeddings (RoPE), ALiBi.

### Feed-Forward Networks (FFN)
-	Capas densas aplicadas por token.
-	Aumentan la capacidad no lineal del modelo.
-	Optimizaciones modernas: SwiGLU, GeGLU.

### Normalizaci√≥n y estabilidad
-	LayerNorm / RMSNorm.
-	Residual connections para evitar degradaci√≥n del gradiente.
-	Criticales para entrenar modelos muy profundos.

## Funcionamiento interno

### Tokenizaci√≥n
-	Conversi√≥n de texto a tokens num√©ricos.
-	M√©todos comunes: BPE, WordPiece, SentencePiece.
-	Impacta directamente en eficiencia y calidad multiling√ºe.

### Flujo de inferencia
-	Entrada ‚Üí tokenizaci√≥n ‚Üí embeddings.
-	Pasos secuenciales de atenci√≥n + FFN por capa.
-	C√°lculo de probabilidades (softmax).
-	Selecci√≥n del siguiente token (sampling).

### Decodificaci√≥n
-	Greedy decoding.
-	Beam search.
-	Top-k / Top-p (nucleus sampling).
-	Temperature para control de creatividad.

### Ventana de contexto
-	L√≠mite m√°ximo de tokens procesables.
-	Influye en memoria, coherencia y costo.
-	Extensiones: sliding window, atenci√≥n jer√°rquica, memoria externa.

## Entrenamiento de LLM

### Preentrenamiento
-	Aprendizaje autoregresivo (predicci√≥n del siguiente token).
-	Datos masivos no etiquetados.
-	Objetivo: modelar distribuci√≥n del lenguaje.

### Fine-tuning
-	Ajuste con datos espec√≠ficos (instrucciones, dominio).
-	Supervisado o semisupervisado.
-	Reduce errores y mejora alineaci√≥n.

### RLHF
-	Reinforcement Learning from Human Feedback.
-	Comparaciones humanas ‚Üí modelo de recompensa.
-	Optimizaci√≥n del comportamiento del modelo.

### T√©cnicas de eficiencia
-	LoRA / QLoRA.
-	Prefix tuning / adapters.
-	Distillation (teacher ‚Üí student).
-	Checkpointing y sharding.

## Desarrollo de sistemas con LLM

### Dise√±o de prompts
-	Instrucciones claras y estructuradas.
-	Ejemplos (few-shot).
-	Separaci√≥n de contexto, tarea y formato de salida.

### Arquitecturas de aplicaci√≥n
-	LLM como servicio (API).
-	RAG con bases vectoriales.
-	Agentes con herramientas.
-	Pipelines s√≠ncronos y as√≠ncronos.

### Integraci√≥n con sistemas
-	APIs REST / gRPC.
-	Conectores a bases de datos, archivos y servicios.
-	Automatizaci√≥n de flujos de trabajo.

### Testing y evaluaci√≥n
-	Tests determin√≠sticos con prompts controlados.
-	Evaluaci√≥n autom√°tica y humana.
-	Monitoreo en producci√≥n.

## Optimizaci√≥n y despliegue

### Serving
-	Modelos locales vs remotos.
-	Batching din√°mico.
-	Caching de respuestas y embeddings.

### Optimizaci√≥n de inferencia
-	Cuantizaci√≥n (INT8, INT4).
-	Compilaci√≥n (Torch Compile, TensorRT).
-	Ejecuci√≥n en GPU, TPU o edge.

### Escalado
-	Autoscaling por demanda.
-	Load balancing.
-	Separaci√≥n de c√≥mputo y almacenamiento.

## Seguridad y control

### Guardrails
-	Filtrado de entradas y salidas.
-	Restricciones por dominio.
-	Validaci√≥n estructural de respuestas.

### Alineaci√≥n
-	Pol√≠ticas de comportamiento.
-	Reducci√≥n de sesgos.
-	Control de alucinaciones mediante grounding.

# LLM ‚Äî Casos de uso e implementaci√≥n

## Casos de uso generales

### Chatbots y asistentes virtuales
-	**Atenci√≥n al cliente**: respuestas autom√°ticas a preguntas frecuentes.
-	**Soporte t√©cnico**: diagn√≥stico guiado y resoluci√≥n de incidencias.
-	**Agentes conversacionales**: integraci√≥n con CRM y sistemas internos.
-	Ejemplo: Chatbot de e-commerce que recomienda productos seg√∫n historial de usuario.

### Generaci√≥n de contenido
-	Textos creativos: blogs, guiones, art√≠culos.
-	Summary / abstracci√≥n de documentos largos.
-	C√≥digo autom√°tico y snippets de programaci√≥n.
-	Ejemplo: Generaci√≥n de reportes financieros diarios a partir de datos en Excel.

### Traducci√≥n y multiling√ºismo
-	Traducci√≥n autom√°tica con contexto y estilo adaptativo.
-	Localizaci√≥n de aplicaciones y contenido web.
-	Ejemplo: Traducci√≥n de manuales t√©cnicos manteniendo terminolog√≠a espec√≠fica.

### An√°lisis y extracci√≥n de informaci√≥n
-	Clasificaci√≥n de documentos.
-	Extracci√≥n de entidades y relaciones.
-	An√°lisis de sentimiento y tendencias.
-	Ejemplo: RASTreo de menciones de marca y opini√≥n p√∫blica en redes sociales.

### Automatizaci√≥n y agentes inteligentes
-	Automatizaci√≥n de tareas repetitivas.
-	Agentes aut√≥nomos capaces de ejecutar pasos secuenciales.
-	Ejemplo: Asistente que crea tickets de soporte, asigna prioridad y env√≠a correos autom√°ticamente.

## Implementaci√≥n t√©cnica

### Arquitectura b√°sica
-	**Entrada de texto ‚Üí Tokenizaci√≥n ‚Üí LLM ‚Üí Decodificaci√≥n ‚Üí Output**
-	Conexi√≥n a bases de datos, APIs o servicios externos.
-	Posibilidad de RAG para mejorar precisi√≥n y reducir alucinaciones.

### Ejemplo de configuraci√≥n de pipeline (Python + LangChain)
{% raw %}
```python
from langchain.llms import OpenAI
from langchain.chains import RetrievalQA
from langchain.vectorstores import FAISS
from langchain.prompts import PromptTemplate

# Configuraci√≥n del modelo
llm = OpenAI(model_name="gpt-4", temperature=0.7, max_tokens=1024)

# Carga de base vectorial
vector_store = FAISS.load_local("vector_index")

# Plantilla de prompt
prompt = PromptTemplate(
    input_variables=["query", "context"],
    template="Contexto: {context}\nPregunta: {query}\nRespuesta:"
)

# Configuraci√≥n de cadena de RAG
qa_chain = RetrievalQA(
    llm=llm,
    retriever=vector_store.as_retriever(),
    prompt=prompt
)

# Ejecuci√≥n
query = "Resumen de los KPIs de marketing Q4"
result = qa_chain.run(query)
print(result)
```
{% endraw %}`

### Ejemplo de despliegue en FastAPI

{% raw %}
```python
from fastapi import FastAPI, Request
from langchain.chains import LLMChain

app = FastAPI()
chain = LLMChain(llm=llm, prompt=prompt)

@app.post("/query")
async def query_endpoint(req: Request):
    data = await req.json()
    user_query = data.get("query")
    response = chain.run({"query": user_query})
    return {"answer": response}
```
{% endraw %}

### Ejemplo de configuraci√≥n RAG con vector DB (FAISS)

* **Ingesti√≥n**: documentos ‚Üí embeddings ‚Üí vector DB.
* **Consulta**: usuario ‚Üí embeddings ‚Üí b√∫squeda por similitud ‚Üí contexto ‚Üí LLM.
* **Output**: respuesta fundamentada en documentos.
* Configuraciones recomendadas:

  * Vector dimension: 1536 (dependiendo del modelo).
  * Top-k: 5‚Äì10 resultados para contexto.
  * Batching: 16‚Äì32 consultas para eficiencia.

### Ejemplo de agente aut√≥nomo

* **Uso**: realizar tareas encadenadas con decisiones condicionadas.
* Configuraci√≥n:

  * Modelo base: Llama 4 o Gemini 2.5.
  * Tools: APIs internas, web scraping, base de datos.
  * Memory: almacenamiento de historial de conversaci√≥n y contexto relevante.
  * Workflow:

    1. Usuario da instrucci√≥n.
    2. Agente decide pasos a ejecutar.
    3. Consulta herramientas y genera respuesta.
    4. Actualiza memoria y contexto.

## Casos de uso en la empresa

* [Data Science](/data%20science/data-science/): an√°lisis de grandes vol√∫menes de texto y extracci√≥n de insights.
* IA: integraci√≥n de agentes aut√≥nomos y automatizaci√≥n de decisiones.
* [cloud](/cloud/cloud/): despliegue escalable y optimizado de pipelines RAG y modelos LLM.
